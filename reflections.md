Reflections
===========

<!--
This file generated by the build script at ./Build.hs from the files in
./reflections.  If you want to edit this, edit those instead!
-->

Table of Contents
-----------------

* [Day 1](#day-1)
* [Day 2](#day-2)
* [Day 3](#day-3)
* [Day 4](#day-4)
* [Day 5](#day-5)
* [Day 6](#day-6)
* [Day 7](#day-7)
* [Day 8](#day-8)
* [Day 9](#day-9)
* [Day 10](#day-10)
* [Day 11](#day-11)
* [Day 12](#day-12)
* [Day 13](#day-13)
* [Day 14](#day-14)
* [Day 15](#day-15)
* [Day 16](#day-16)
* [Day 17](#day-17)
* [Day 18](#day-18)
* [Day 19](#day-19) *(no reflection yet)*
* [Day 20](#day-20) *(no reflection yet)*
* [Day 21](#day-21) *(no reflection yet)*
* [Day 22](#day-22) *(no reflection yet)*
* [Day 23](#day-23) *(no reflection yet)*
* [Day 24](#day-24) *(no reflection yet)*
* [Day 25](#day-25)

Day 1
------

<!--
This section is generated and compiled by the build script at ./Build.hs from
the file `./reflections/day01.md`.  If you want to edit this, edit
that file instead!
-->

*[Prompt][d01p]* / *[Code][d01g]*

[d01p]: https://adventofcode.com/2021/day/1
[d01g]: https://github.com/egnwd/advent/blob/2021/src/AOC/Challenge/Day01.hs

Reading a list of ints always seems to be early on, we can do that easily with:

```haskell
parser = map read . lines
```

Then for part 1 we need to get the differences, which can be achieved by dropping the head of the
list then subtracting the two lists element-wise:

```haskell
differences x = zipWith subtract x (tail x)
```

_N.B. `subtract` is just `-` with the arguments flipped, useful for partial application._

and then to get the answer we need only the increases we just filter for where we got a postitive result:

```haskell
part1 = length . filter (>0) . differences
```

Yay! 1 star!

For part 2 we can reuse the differences logic from part 1, we just need to construct a new input list using the windows.
The easiest way to do this given the window is only length 3 is use the version of `zipWith` that takes 3 lists, this time with addition.

```haskell
summedSlidingWindows x = zipWith3 (\a b c -> a + b + c) x (drop 1 x) (drop 2 x)
```

Then to solve we just use part 1.

```haskell
part2 = part1 . summedSlidingWindows
```

Day 1 complete!


### Day 1 Benchmarks

```
>> Day 01a
benchmarking...
time                 47.27 μs   (46.45 μs .. 48.43 μs)
                     0.994 R²   (0.990 R² .. 0.997 R²)
mean                 47.09 μs   (45.79 μs .. 48.64 μs)
std dev              4.412 μs   (3.534 μs .. 5.703 μs)
variance introduced by outliers: 82% (severely inflated)

* parsing and formatting times excluded

>> Day 01b
benchmarking...
time                 208.5 μs   (202.4 μs .. 214.6 μs)
                     0.994 R²   (0.990 R² .. 0.997 R²)
mean                 210.7 μs   (206.9 μs .. 216.4 μs)
std dev              15.33 μs   (10.99 μs .. 20.72 μs)
variance introduced by outliers: 67% (severely inflated)

* parsing and formatting times excluded
```



Day 2
------

<!--
This section is generated and compiled by the build script at ./Build.hs from
the file `./reflections/day02.md`.  If you want to edit this, edit
that file instead!
-->

*[Prompt][d02p]* / *[Code][d02g]*

[d02p]: https://adventofcode.com/2021/day/2
[d02g]: https://github.com/egnwd/advent/blob/2021/src/AOC/Challenge/Day02.hs

Moving around a 2D map, another AoC classic challenge.

My initial solution used recursion and word splitting for the solution,
the second used State, and that too was more difficult to understand, and felt more imperative.

The version here uses Monoids to combine the values (part a ended up similar to my first fold attempt).

To parse we can read many `Sum`mable `Points` and have that as our instruction set.
The parser combinators make this quite nice to do:

```haskell
parser = do
  dir <- pTok $
        (Sum . flip V2 0     <$ "forward")
    <|> (Sum . V2 0 . negate <$ "up")
    <|> (Sum . V2 0          <$ "down")
  dir <$> pDecimal
```

Then to solve part 1 we just need to combine the instructions.
I used the `V2` type from `Linear.V2` to represent points as they are 2D vectors with the added bonus of
being able to easily to component-wise addition of vectors.

```haskell
solve = product . getSum . mconcat
```

After the submarine's epic journey, we get 1 star!

For part two, I wrote a new type `Submarine` with a location and aim.

```haskell
data Submarine = Sub { loc :: Point, aim :: Int }
```

this time to combine we must implement `Monoid`, and first Semigroup.

```haskell
instance Semigroup Submarine where
    (Sub v a) <> (Sub (V2 x' y') a') = Sub (v + V2 x' (y' + x' * a)) (a + a')

instance Monoid Submarine where
    mempty = Sub (pure 0) 0
    mconcat = foldl (<>) mempty
```

`(<>)` combines two commands, adding the forward components `x+x'`,
updates the depth taking into account the previous aim and the forward distance
`y + y' + x' * a` (for the `up` & `down` commands `x'` & `y'` are `0` so that term cancels),
and finally the aim is updated (for `forward` this is `0` so is also a noop).

Then to combine we do similar to part 1:
```haskell
solve = product . loc . mconcat
```

where `loc` gets the vector from the `Submarine` akin to `getSum` getting the vector from `Sum`.

Submarine successfully piloted!


### Day 2 Benchmarks

```
>> Day 02a
benchmarking...
time                 3.811 ms   (3.759 ms .. 3.889 ms)
                     0.997 R²   (0.995 R² .. 0.999 R²)
mean                 3.781 ms   (3.721 ms .. 3.821 ms)
std dev              164.2 μs   (126.4 μs .. 240.8 μs)
variance introduced by outliers: 25% (moderately inflated)

>> Day 02b
benchmarking...
time                 2.332 ms   (2.310 ms .. 2.357 ms)
                     0.999 R²   (0.999 R² .. 1.000 R²)
mean                 2.345 ms   (2.330 ms .. 2.363 ms)
std dev              54.61 μs   (42.35 μs .. 69.57 μs)
variance introduced by outliers: 10% (moderately inflated)
```



Day 3
------

<!--
This section is generated and compiled by the build script at ./Build.hs from
the file `./reflections/day03.md`.  If you want to edit this, edit
that file instead!
-->

*[Prompt][d03p]* / *[Code][d03g]*

[d03p]: https://adventofcode.com/2021/day/3
[d03g]: https://github.com/egnwd/advent/blob/2021/src/AOC/Challenge/Day03.hs

I have not really liked any of the iterations of Day 3, but I learnt something new for this one, so I'm happy with that.

I learnt about [apomorphisms](https://ipfs.io/ipfs/QmTppu1VDAQWsdiyVSZX6qb8PErdpwzNP2oKfEhcgaBvWR/guide-to-morphisms.pdf)!

Before we get there though, let's look at part 1.

We have many rows of binary numbers, so we need to parse the strings into a many lists of bits.
I'm going to use the following data types:

```haskell
type Bit = Finite 2
type Bits = [Bit]

zero, one :: Bit
zero = finite 0
one  = finite 1
```

`Finite 2` represents a number type that has two inhabitants, `0` and `1`.

So in order to parse we can simply do

```haskell
parser :: String -> [Bits]
parser = map (map (finite . fromIntegral . digitToInt)) . lines
```

For part 1 we need to collect a binary number for the most common bits in each column,
and a binary number for the least common bits. We can do this by transposing the matrix of bits so that we are iterating over the columns and getting the most and least significant bit.

```haskell
-- | Count the number of 1s and 0s, then compare
mostCommonBit :: Bits -> Bit
mostCommonBit bs = if ones > zeros then one else zero
    where
        (zeros, ones) = foldr go (0,0) bs
        go :: Bit -> (Int, Int) -> (Int, Int)
        go 0 = first succ
        go 1 = second succ
        go _ = id

-- | Note the least common bit will just be the most common bit flipped
mostAndLeastCommonBit :: Bits -> (Bit, Bit)
mostAndLeastCommonBit bs = let b = mostCommonBit bs in (b, 1-b)

getMostAndLeastCommonBitsPerColumn :: [Bits] -> [(Bit, Bit)]
getMostAndLeastCommonBitsPerColumn = map mostAndLeastCommonBit . transpose
```

Now that we have these values we need to turn the binary numbers to decimals and multiply them together.

```haskell
solve bs = let (gamma, epsilon) = unzip (getMostAndLeastCommonBitsPerColumn bs)
            in gamma * epsilon
```

_If you aren't familiar, `unzip` takes a list of pairs (`[(a,b)]`) and creates a pair of lists `([a], [b])`._

Part 1 done!

Part 2 is where we get into _apomorphisms_.

Firstly, I found [this blog post](https://blog.sumtypeofway.com/posts/recursion-schemes-part-3.html) useful to give an insight into how _apomorphisms_ are constructed.

To very poorly summarise: an _apomorphism_ is the dual of a _paramorphism_, which in turn is a _catamorphism_ but with additional context of the structure that you are recursing on.
A _catamorphism_ is a way to collapse a structure down to some value, and is the most familar of the _-morphisms_,
for example `foldr`, `sum` & `length` are all catamorphisms (I'm pretty sure).
So a _paramorphism_ is a way of collasing a structure down to a value, but at each stage you have some additional context of the unmodified structure. If it helps the types (I'm using the list functor here for ease) look like this:

```haskell
cata :: ([a] ->       b)  -> [a] -> b
para :: ([a] -> ([a], b)) -> [a] -> b
```

So, an _apomorphism_ is the dual of the _paramorphism_, and the way I have tried to think of it (which may be wrong) is:
you take a seed value and build a structure by providing either the rest of the structure, or a bit of the structure and the next seed. The type is roughly:

```haskell
apo :: (b -> Either [a] (a, b)) -> b -> [a]
```

So... how do we use this...

Going back to the problem we need to calculate the oxygen rating and carbon dioxide rating and multiply them together.
To get the oxygen rating we need to find the number matches the **most common bit** of each column by filtering out numbers that don't match until we are left with one.

_From here I will use the non specific type of `apo`._

Here is the base functor for a list.
I'm not going to go into what that is, but the structure looks a lot like a cons list and
it basically has some part of the list structure in the `Cons a` then keeps the rest of the structure in `b`.
For much better information I would recommend [this blog post](https://blog.sumtypeofway.com/posts/recursion-schemes-part-4-point-5.html).

```haskell
data ListF a b = Nil | Cons a b
```

Now we can think about our initial seed: the rows of binary numbers.
And what we can to produce: a list of bits that represent the oxygen rating (for now).

```haskell
oxygen :: [Bits] -> ListF Bit (Either Bits [Bits])
oxygen bs = ...
```

This looks sort of like the type definition from earlier for `apo`, the main difference is the `(a, b)` is now a `ListF` wrapping the `Either`.

The next task for the oxygen rating is to work out the **most common bit** for the column.

```haskell
mcb = (mostCommonBit . map head) bs
```

We can do this by reusing our `mostCommonBit` function from part 1 and running it on the head of each binary number in our seed.

Next, we need to get all the numbers in the seed that start with this `mcb`.

```haskell
ns = filter ((== mcb) . head) bs
```

Again fairly simple, just filter the list where the head is equal to the **most common bit**.

The final part is the interesting part:

```haskell
go = case ns of
    []  -> Nil -- There are no numbers (uh no, the problem might be broken)
    -- If there is only one number left,
    -- return part of the structure: the current mcb cons'd to all the remain bits of the final number
    [n] -> Cons mcb (Left (tail n))
    -- For anything else,
    -- return part of the structure: the current mcb cons'd to the next seed
    -- (all the binary numbers after removing the current column)
    _   -> Cons mcb (Right (map tail ns))
```

Visually it looks a little like doing this:

```
Current seed:

0 | 0 1 0 0
1 | 1 1 1 0
1 | 0 1 1 0
1 | 0 1 1 1

Filtered:

1 | 1 1 1 0
1 | 0 1 1 0
1 | 0 1 1 1

Next Seed:
Cons 1 (
    1 | 1 1 0
    0 | 1 1 0
    0 | 1 1 1)
```

The carbon dioxide follows the same pattern, we just use **least common bit** not **most common bit**.
Finally, we get teh values and multiply them together:

```haskell
solve bs = o * c
    where
        o = binToDec $ apo oxygen bs
        c = binToDec $ apo carbonDioxide bs
```

Phew! and Done!


### Day 3 Benchmarks

```
>> Day 03a
benchmarking...
time                 2.616 ms   (2.580 ms .. 2.653 ms)
                     0.998 R²   (0.996 R² .. 0.999 R²)
mean                 2.579 ms   (2.545 ms .. 2.617 ms)
std dev              127.0 μs   (94.73 μs .. 169.5 μs)
variance introduced by outliers: 31% (moderately inflated)

* parsing and formatting times excluded

>> Day 03b
benchmarking...
time                 509.8 μs   (508.6 μs .. 511.3 μs)
                     1.000 R²   (1.000 R² .. 1.000 R²)
mean                 508.9 μs   (508.1 μs .. 510.1 μs)
std dev              3.314 μs   (2.671 μs .. 4.362 μs)

* parsing and formatting times excluded
```



Day 4
------

<!--
This section is generated and compiled by the build script at ./Build.hs from
the file `./reflections/day04.md`.  If you want to edit this, edit
that file instead!
-->

*[Prompt][d04p]* / *[Code][d04g]*

[d04p]: https://adventofcode.com/2021/day/4
[d04g]: https://github.com/egnwd/advent/blob/2021/src/AOC/Challenge/Day04.hs

Bingo against a giant squid is a funny idea 😆

Today we got to learn about two Semigroups! `First` and `Last`,
they are fairly self explanatory, `First` will give you the left (first) argument to `(<>)`
and `Last` will give you the second (last) argument to `(<>)`.

_N.B. `Last` is the `Dual` of `First`._

To parse we need two things, the list of numbers and all the cards.

```haskell
data BingoNumber = Unmarked Int | Marked Int deriving (Eq, Show)
type BingoCard = [[BingoNumber]]

parse :: String -> ([Int], [BingoCard])
```

Here we can represent a number as either marked or unmarked (note this is just `Either` with a nicer name).

Then we can define our solve function to take the list of numbers, the boards, and return the score, maybe.

```haskell
solve :: [Int] -> [BingoCard] -> Maybe Score
```

(We will look at `Score` later.)

Then as we see a number, `n`, we mark all our cards.

```haskell
newCards n cards = cards'
  where
    cards' = cards <&> mapped.mapped %~ mark
    mark (Unmarked x) | x == n = Marked x
    mark x = x
```

We can define what it means for a card to have won:

```haskell
winner :: BingoCard -> Bool
winner cards = row cards || column cards
    where
        column = row . transpose
        row = any (all isMarked)

isMarked :: BingoNumber -> Bool
isMarked = \case
    Marked _ -> True
    _ -> False
```

Next, we work out the scores for all the winners this round.

```haskell
scoreWinners cards' n = winners
  where
      winners = foldMap (Just . First . scoreCard) w
      w = filter winner cards'
      scoreCard card = (sum . unmarked $ card) * n
      unmarked = map unmarkedValue . concat

unmarkedValue :: BingoNumber -> Int
unmarkedValue (Unmarked n) = n
unmarkedValue (Marked _)   = 0
```

and here is where we get to see `First`.

We've taken our cards and found the winners, then we score them using the score system from the problem statement,
and next we make a `Maybe (First Int)` with `Just . First`. This represents (the maybe is to represent the fact we have a score).

`foldMap` will the return `Nothing` if there are no winners this round, or `Just (First x)` where `x` is the score of the first winner.

We then recurse on the rest of the numbers and the boards that haven't won yet.

```haskell
solve (n:ns) cards = scoreWinners cards' n <> solve ns (filter (not . winner) cards')
  where
    cards' = newCards n cards
```

Now for part two all we need to do is swap `First` for `Last`!!

Now, hopefully the squid doesn't eat us.


### Day 4 Benchmarks

```
>> Day 04a
benchmarking...
time                 15.18 ms   (14.92 ms .. 15.40 ms)
                     0.998 R²   (0.997 R² .. 0.999 R²)
mean                 15.10 ms   (14.94 ms .. 15.24 ms)
std dev              380.8 μs   (270.1 μs .. 579.1 μs)

* parsing and formatting times excluded

>> Day 04b
benchmarking...
time                 20.12 ms   (19.95 ms .. 20.35 ms)
                     1.000 R²   (0.999 R² .. 1.000 R²)
mean                 20.05 ms   (19.94 ms .. 20.14 ms)
std dev              231.6 μs   (169.9 μs .. 321.9 μs)

* parsing and formatting times excluded
```



Day 5
------

<!--
This section is generated and compiled by the build script at ./Build.hs from
the file `./reflections/day05.md`.  If you want to edit this, edit
that file instead!
-->

*[Prompt][d05p]* / *[Code][d05g]*

[d05p]: https://adventofcode.com/2021/day/5
[d05g]: https://github.com/egnwd/advent/blob/2021/src/AOC/Challenge/Day05.hs

Lots of 2D grids!

Another day we get to use the `Linear` package. We can model a line as a 2D vector of points (`V2 (V2 Int)`).

For part 1 we are told to ignore diagonal lines (I wonder what part 2 could possibly be!) so we can filter those easily enough:

```haskell
isHorizontalOrVertical :: V2 (V2 Int) -> Bool
isHorizontalOrVertical (V2 (V2 x1 y1) (V2 x2 y2)) = x1 == x2 || y1 == y2

horizontalOrVerticalLines :: [V2 (V2 Int)] -> [V2 (V2 Int)]
horizontalOrVerticalLines lines = filter isHorizontalOrVertical lines
```

Next, we need to generate the full lines. If we take 2 points `a` & `b` and find their difference `b - a`,
then we can get the vector between them. Reducing this vector to it's simplest form by dividing each component by the greatest common divisor
of the components will give us the smallest possible hops we can make to hit a valid grid point.
We then make little hops and collect the points in a list.

This is a modified version of [mstksg's](https://github.com/mstksg/advent-of-code-2020/blob/master/src/AOC/Common/Point.hs#L371) `lineTo` function from last years AOC.

```haskell
lineTo :: V2 Point -> [Point]
lineTo (V2 p0 p1) = [p0 + t *^ step | t <- [0 .. gcf]]
  where
    d@(V2 dx dy) = p1 - p0
    gcf          = gcd dx dy
    step         = (`div` gcf) <$> d
```

and as the tooltip hinted, we are looking along the lines of plotting lines so the [Bresenham's line algorithm](https://en.wikipedia.org/wiki/Bresenham%27s_line_algorithm#Algorithm_for_integer_arithmetic) is a nice read, though not necessarily useful for the problem other than providing intuition.

Then all we need to do find the frequency of getting all the points from all the line segments:

```haskell
pointFrequencies lines = fromMapWith (+) . map (,1) . concatMap lineTo $ lines
```

Then finally find the number of points that are visited by more than 1 line segment.

```haskell
solve lines = size . filter (>1) . pointFrequencies $ lines
```

Done! 1 star!

As suspected, part 2 removes the horizontal/vertical line restriction, and so we need simply remove our filter.

Hydrothermal vent field successfully navigated!


### Day 5 Benchmarks

```
>> Day 05a
benchmarking...
time                 222.4 ms   (211.9 ms .. 236.0 ms)
                     0.998 R²   (0.994 R² .. 1.000 R²)
mean                 218.0 ms   (214.7 ms .. 222.0 ms)
std dev              5.663 ms   (3.912 ms .. 7.234 ms)
variance introduced by outliers: 14% (moderately inflated)

* parsing and formatting times excluded

>> Day 05b
benchmarking...
time                 381.1 ms   (370.1 ms .. 399.2 ms)
                     1.000 R²   (0.999 R² .. 1.000 R²)
mean                 377.9 ms   (371.5 ms .. 381.7 ms)
std dev              6.356 ms   (2.334 ms .. 8.720 ms)
variance introduced by outliers: 19% (moderately inflated)

* parsing and formatting times excluded
```



Day 6
------

<!--
This section is generated and compiled by the build script at ./Build.hs from
the file `./reflections/day06.md`.  If you want to edit this, edit
that file instead!
-->

*[Prompt][d06p]* / *[Code][d06g]*

[d06p]: https://adventofcode.com/2021/day/6
[d06g]: https://github.com/egnwd/advent/blob/2021/src/AOC/Challenge/Day06.hs

For part 1 today I started with the most naïve approach where I simply generate all the fish and then count them,
fully aware this wouldn't scale, but it might get me the first star.

So for this approach we take a fish and generate a list of fish that come from this fish in the next day.

```haskell
step 0 = [6,8]
step f = [f-1]
```

next we map all of today's fish into their offspring, and join all the lists. Now we simply repeat the process until the nth day and see how many fish we have.

```haskell
solve = length . (!! n) . iterate (concatMap step)
```

Now fortuneately for only 80 days that didn't take to long, onto part 2.

First, I tried what I imagine most people did which was change the number to 256 and rerun.
I was sat there for a while... it didn't work.

In order to speed up the process we can notice something interesting:
if you have a fish that is on day N, over the course of 256 days it will have so many fish descendants,
following some family tree shape. (it's 4726100874 descendants, in case you are curious).

What is more is that if another fish starts on 4, then it will also have 4726100874 descendants.
So we can see that if there are N 4s in the input then we get `N * 4726100874` descendants.

As there are finitely many numbers that the fish can be represented by (0-8) we represent them not as a `[Int]` but as a very small `Map Int Int` where the key is the fish value and the value is the count of fish in that slot.

Everyday, there will be all the fish from the `0` slot making new fish, so we get `n` new fish in the `8` slot and `n` fish into the `6` "reset" slot. All the other fish shift down by one.

At the end of 256 days we can count the numbers in the map to see how many fish there are.

```haskell
solve :: Int -> [Fish] -> Int
solve n = sum . (!! n) . iterate step . freqs

step :: Map Fish Int -> Map Fish Int
step m = M.insertWith (+) 6 newFish . M.mapKeys tickDown $ m
    where
        newFish = m ! 0
        tickDown = maybe 8 weaken . unshift
```

_`maybe 8 weaken . unshift` represents wrapping the numbers around, 6 -> 5, 2 -> 1, and 0 -> 8 (as `unshift 0` will return `Nothing`, so we reset it to 8)_

To me it makes more sense to think about the fish resetting to `8` and new fish coming in at `6`, just so the wrapping and insertion keeps the fish the same... but that's just me.


### Day 6 Benchmarks

```
>> Day 06a
benchmarking...
time                 120.8 μs   (120.6 μs .. 121.1 μs)
                     1.000 R²   (1.000 R² .. 1.000 R²)
mean                 120.9 μs   (120.6 μs .. 121.3 μs)
std dev              1.187 μs   (932.3 ns .. 1.760 μs)

* parsing and formatting times excluded

>> Day 06b
benchmarking...
time                 402.4 μs   (400.9 μs .. 404.4 μs)
                     1.000 R²   (1.000 R² .. 1.000 R²)
mean                 400.2 μs   (399.0 μs .. 401.9 μs)
std dev              4.823 μs   (3.643 μs .. 6.416 μs)

* parsing and formatting times excluded
```



Day 7
------

<!--
This section is generated and compiled by the build script at ./Build.hs from
the file `./reflections/day07.md`.  If you want to edit this, edit
that file instead!
-->

*[Prompt][d07p]* / *[Code][d07g]*

[d07p]: https://adventofcode.com/2021/day/7
[d07g]: https://github.com/egnwd/advent/blob/2021/src/AOC/Challenge/Day07.hs

I feel like there is a better solution for today that avoids checking all points, but for now here is the naïve version:

For part 1 we need a way of scoring a particular horizontal position.
The score here is the sum of the absolute differences from the crabs to the position in question.

```haskell
score :: [Int] -> Int -> Int
score crabs position = sum . map (abs . subtract position) $ crabs
```

The we need to check all the positions from the minimum crab to the maximum crab.

```haskell
solve [Int] -> Int
solve crabs = minimum . map (score crabs) $ [minimum cs .. maximum cs]
```

And there we go!

For part 2, then need to confess my original implementation of part 1 was:

```haskell
solve [Int] -> Int
solve crabs = minimum . map (score crabs) $ crabs
```

as I assumed we had to pick a crab for them to congregate on,
and one of my crabs was on the right spot.

For part 2 I then just needed to tweak the score function to be

```haskell
triangularNumber :: Int -> Int
triangularNumber x = x * (x + 1) `div` 2

score :: [Int] -> Int -> Int
score crabs position = sum . map (triangularNumber . abs . subtract position) $ crabs
```

_...and then you debug why you can't get the right answer and think you can no longer remember what a triangular number is for 20 minutes,
despite watching absurds amounts of [sudoku videos](https://www.youtube.com/c/CrackingTheCryptic)..._

...until you realise all the crabs could congregate on any of the spots.

_sigh._


### Day 7 Benchmarks

```
>> Day 07a
benchmarking...
time                 32.43 ms   (32.06 ms .. 32.90 ms)
                     0.999 R²   (0.999 R² .. 1.000 R²)
mean                 31.91 ms   (31.36 ms .. 32.27 ms)
std dev              947.0 μs   (535.8 μs .. 1.565 ms)

* parsing and formatting times excluded

>> Day 07b
benchmarking...
time                 2.616 s    (NaN s .. 2.654 s)
                     1.000 R²   (1.000 R² .. 1.000 R²)
mean                 2.597 s    (2.591 s .. 2.607 s)
std dev              9.376 ms   (1.954 ms .. 12.41 ms)
variance introduced by outliers: 19% (moderately inflated)

* parsing and formatting times excluded
```



Day 8
------

<!--
This section is generated and compiled by the build script at ./Build.hs from
the file `./reflections/day08.md`.  If you want to edit this, edit
that file instead!
-->

*[Prompt][d08p]* / *[Code][d08g]*

[d08p]: https://adventofcode.com/2021/day/8
[d08g]: https://github.com/egnwd/advent/blob/2021/src/AOC/Challenge/Day08.hs

Firstly, I'm going to parse each row into the following type:

```haskell
type Segments = Set Char
data Entry = Entry { signals :: [Segments], outputs :: [Segments] } deriving (Eq, Show)
```

I chose `Segments` to be a set of characters so that we can compare them ignoring what order they are in.
An entry is then a list of signals, and a list of outputs.

For example, `acedgfb cdfbe gcdfa fbcad dab cefabd cdfgeb eafb cagedb ab | cdfeb fcadb cdfeb cdbaf`
would become

```haskell
Entry { signals = map fromList ["acedgfb", "cdfbe", "gcdfa", "fbcad", "dab", "cefabd", "cdfgeb", "eafb", "cagedb", "ab"]
      , outputs = map fromList ["cdfeb", "fcadb", "cdfeb", "cdbaf"]
      }
```

For part 1 we need to find out how many times 1, 4, 7, or 8 appear in the outputs.

We can do this quite simply using the fact that these four numbers have unique lengths.

```haskell
solve = length . filter (\o -> length o `elem` [2, 3, 4, 7]) . concatMap outputs
```

Part 2 is a bit trickier however.

Let's break down the task into:
 - Finding a **translation** for the **signals** of each row
 - Apply the **translation** to the **outputs** of each row

**Finding the translations:**

At a high level we can do the following:

```haskell
translations  = map (decodeEntry . signals) entries
decodeEntry e = find valid (choices e)
      where
          valid m = maybe False (all (`member` digits)) . traverse (translate m) $ e
```

So here we create a translation for each of the entries signals, and we do this by "decoding the entry".
`decodeEntry` finds a valid from a set of `choices` (we will define choices in a moment),
and a translation is valid if after using the transation on all the signals you are left with each being a digit.

_`digits` is a map of segments to numbers, e.g. `"cf" -> 1` is in the map_

So how do we determine the `choices`?

One option is to brute force all the possible maps from the characters a-g back to a-g.
However, this is slow and we can do better.

Firstly, we can use the unique numbers to massively restrict the list of translations.
Here is the full `choices` function that does just that, then we will break it down.

```haskell
choices :: [Segments] -> [Map Char Char]
choices = pickUnique . toList . fromListWith intersection . concatMap choices'
    where
        chooseFrom s n = toList . Data.Set.map (, n) $ s
        choices' s | size s == 2 = s `chooseFrom` one
                   | size s == 3 = s `chooseFrom` seven
                   | size s == 4 = s `chooseFrom` four
                   | size s == 7 = s `chooseFrom` eight
                   | otherwise = []
```

From the problem we know that any signal of length two will encode a `1`.
So from the example above we know that `"ab"` represents `1` (or `"cf"` as segments).
The issue is we don't know if `'a' -> 'c'` and `'b' -> 'f'`, or if `'a' -> 'f'` and `'b' -> 'c'`.

But we do have some possible options that we can represent as a mapping from `Char` to possible `Chars`.

For example, `"ab"` becomes: `[('a', ['c', 'f']), ('b', ['c', 'f'])]`.

We can then repeat this process for all the unique numbers, et voilà, we have the `choices'` function above!
_`one`, `seven`, ... are constants representing `"cf"`, `"acf"`, ... respectively._

After doing this for all the signals we can make a map from a character to a set of it's options.
To combine the options we've just created we can use set intersection.
As if one choice says that `'b' -> ['c', 'f', 'e']` and another says `'b' -> ['a', 'c', 'f']` we know that `'b' -> ['c', 'f']`.

Next we can turn this into a set of maps that can be created from these options where each input character maps to a unique output character.
Here I used the [`pickUnique` function from mstksg's common library from last year](https://github.com/mstksg/advent-of-code-2020/blob/master/src/AOC/Common.hs#L302).
It's a neat little function that keeps track of which characters are already used in the map and reduces each set of possible options to different maps of each possible pick.

Now that we have a valid map for each entry wew can apply the translation to the outputs.

**Applying the translations:**

```haskell
numberFromDigits :: (Foldable t) => t Int -> Int
numberFromDigits = foldl (\n d -> n * 10 + d) 0

solve :: [Entry] -> Int
solve ds = sum $ zipWith (\e t -> outputToNumber (outputs e) t) ds translations
    where
        outputToNumber o t = numberFromDigits $ map (pickNumber . translate t) o
        pickNumber n       = digits ! n
        translate t        = fromList . map (t !) . toList
        translations       = map (decodeEntry . signals) ds
        decodeEntry e = find valid (choices e)
            where
                valid m = maybe False (all (`member` digits)) . traverse (translate m) $ e
```

We zip each of the rows with the corresponding translation, and turn the translated outputs into a four digit number.

`outputToNumber` takes the outsputs and the translation and translates each output segments then looks up the output in the map of `digits` (`pickNumber`).
In the running example this will map `["cdfeb", "fcadb", "cdfeb", "cdbaf"]` to `["abdfg", "acdfg", "abdfg", "acdfg"]` then to `[5,3,5,3]`.
`numberFromDigits` digits then turns `[5,3,5,3]` into `5353`.

Finally, we sum the number we get from each row.


### Day 8 Benchmarks

```
>> Day 08a
benchmarking...
time                 5.454 ms   (5.400 ms .. 5.518 ms)
                     0.998 R²   (0.997 R² .. 0.999 R²)
mean                 5.501 ms   (5.439 ms .. 5.623 ms)
std dev              270.0 μs   (184.1 μs .. 397.3 μs)
variance introduced by outliers: 26% (moderately inflated)

>> Day 08b
benchmarking...
time                 13.95 ms   (13.58 ms .. 14.56 ms)
                     0.993 R²   (0.984 R² .. 1.000 R²)
mean                 13.67 ms   (13.54 ms .. 14.00 ms)
std dev              477.7 μs   (169.0 μs .. 834.5 μs)
variance introduced by outliers: 11% (moderately inflated)
```



Day 9
------

<!--
This section is generated and compiled by the build script at ./Build.hs from
the file `./reflections/day09.md`.  If you want to edit this, edit
that file instead!
-->

*[Prompt][d09p]* / *[Code][d09g]*

[d09p]: https://adventofcode.com/2021/day/9
[d09g]: https://github.com/egnwd/advent/blob/2021/src/AOC/Challenge/Day09.hs

Part 1 today was simple enough.

Firstly we can parse in the numbers as a `Map (V2 Int) Int`,
and as a cheat for later we can ignore all the spots with `9`, you can imagine them as "super high walls" in our map.

```haskell
type Landscape = Map (V2 Int) Int

parse :: String -> Landscape
parse = parseAsciiMap (mfilter (<9) . pure . digitToInt)
```

where `parseAsciiMap` is a helper method that zips the indexes of a grid with the value,
and a method for generating the value, `Nothing` removes it from the map and `Just x` places `x` into the map.

To find the low points we can filter the map to entries that have values lower than all the neighbours.
To do that we get all the neighbours by adding "North", "East", "South" and "West" to the index in the map (the key).
_N.B. this might result in a point off the map!_

Then we ensure that the current value is less than all these points (if they exist!)
Finally, we can sum all the scores of the low points.

```haskell
score :: Int -> Sum Int
score n = Sum (1+n)

neighbours k = (k +) <$> [V2 0 (-1), V2 1 0, V2 0 1, V2 (-1) 0]

solvea :: Landscape -> Int
solvea = getSum . foldMapWithKey (const score) . findLowPoints
  where
    findLowPoints nss = M.filterWithKey isLowest nss
    isLowest k h = all (maybe True (h <) . (`M.lookup` nss)) (neighbours k)
```

Now for part 2!

For part 2, I used another _apomorphism_! We are tasked with find the product of the sizes of the 3 largest basins.
Our first task is to find the sizes of the basins. All basins have a sink which is the lowest point, so we can map over these and build the basin from this _seed point_.

First let's generate the seeds, we simply find the low points as before, get the locations and turn it into a tuple of `(seen, pointsToCompute)`:

```haskell
lowPointSeeds = map (\l -> (S.empty, S.singleton l)) . M.keys . findLowPoints $ land
```

now we build our basins from a given seed.

```haskell
buildBasin
    :: M.Map Point (S.Set Point)                           -- | Map from point to neighbouring values
    -> Landscape                                           -- | Original grid
    -> (S.Set Point, S.Set Point)                          -- | Seen points, and next points
    -> ListF Int (Either [Int] (S.Set Point, S.Set Point)) -- | ListF of current region sizes over the next regions to visit
buildBasin ns land (seen, next) = Cons (S.size next) go
    where
        neighbouringBasinLocations = M.keysSet . M.restrictKeys land . S.unions . S.map (fromMaybe S.empty . (`M.lookup` ns))
        next' = neighbouringBasinLocations next `S.difference` seen
        seen' = S.union seen next
        go = if null next'
                then Left []
                else Right (seen', next')
```

Here we find all the neighbouring basin locations by looking up the neighbours for our each of our next points to look at,
We then union all these neighbouring points, and intersect the points with our land (to remove any off the edge).

We then remove from this set all the points we've seen before.

If there is nothing in this set we have found the full region, so we finish by returning `Left []`,
otherwise we return `Right (seen', next')` where `seen'` is the union of what we've seen with the points we have just computed.

To build the `ListF` functor we have `Cons (S.size next)` which adds the size of the sub-basin we have just computed to the list.

Then to get the sum we run `sum . apo (buildBasin allNeighbours land) $ lowPointSeeds` where

```haskell
allNeighbours = M.mapWithKey (const . S.fromList . neighbours) land
```

now that we have all the region sizes we find the largest 3 and get the product.

```haskell
solveb :: Landscape -> Int
solveb land = product . largest 3 . map getBasinSize $ lowPointSeeds
    where
        largest n = take n . sortOn negate
        getBasinSize = sum . apo (buildBasin allNeighbours land)
        allNeighbours = M.mapWithKey (const . S.fromList . neighbours) land
        lowPointSeeds = map (\l -> (S.empty, S.singleton l)) . M.keys . findLowPoints $ land
```

And there we are!


### Day 9 Benchmarks

```
>> Day 09a
benchmarking...
time                 16.80 ms   (16.69 ms .. 16.90 ms)
                     1.000 R²   (0.999 R² .. 1.000 R²)
mean                 16.82 ms   (16.76 ms .. 16.90 ms)
std dev              170.5 μs   (115.6 μs .. 283.9 μs)

* parsing and formatting times excluded

>> Day 09b
benchmarking...
time                 42.39 ms   (42.21 ms .. 42.52 ms)
                     1.000 R²   (1.000 R² .. 1.000 R²)
mean                 42.62 ms   (42.48 ms .. 42.87 ms)
std dev              362.9 μs   (216.1 μs .. 577.9 μs)

* parsing and formatting times excluded
```



Day 10
------

<!--
This section is generated and compiled by the build script at ./Build.hs from
the file `./reflections/day10.md`.  If you want to edit this, edit
that file instead!
-->

*[Prompt][d10p]* / *[Code][d10g]*

[d10p]: https://adventofcode.com/2021/day/10
[d10g]: https://github.com/egnwd/advent/blob/2021/src/AOC/Challenge/Day10.hs

For Day 10 I kept it simple and didn't do anything _too_ fancy.

Parsing is straight forward, we just split the lines.

For part 1 we are looking for the sum of the scores of the incorrect brackets.

We can do this by keeping track of a stack of open brackets,
then breaking when we hit a closing bracket that mis-matches.

```haskell
solvea :: String -> Maybe (Sum Integer)
solvea [] = Nothing
solvea (b:bs) = solve' bs [b]
    where
        solve' [] _ = Nothing
        solve' (_:_) [] = Nothing
        solve' (b':bs') (o:os) | b' `elem` "({[<"                       = solve' bs' (b':o:os)
                               | [o,b'] `elem` ["()", "[]", "{}", "<>"] = solve' bs' os
                               | otherwise                              = Just $ scorea b'
```

`Nothing` means that there was no incorrect bracket,
`Just` returns the score of the incorrect bracket as a `Sum`.

The logic of `solve'` returns `Nothing` if either of our tracking lists is empty.
Otherwise, we have one of the following conditions:

1. if we encounter an opening bracket: we push it onto the stack and recurse on the rest of the list.
1. otherwise we have a closing bracket, but if it's matching:
we recurse on the rest of the list, removing the opening bracket from the stack.
1. finally, we have the case where we have an incorrect bracket: we score the bracket and return it.

The score function is a simple lookup:

```haskell
scorea :: Char -> Sum Integer
scorea = \case
    ')' -> Sum 3
    ']' -> Sum 57
    '}' -> Sum 1197
    '>' -> Sum 25137
    _   -> mempty
```

To get the score of everything we can then aggregate the scores we get from all the lines:

```haskell
solve bs = getSum <$> foldMap solvea bs
```

_N.B. `Maybe (Sum Int)` works nicely with the `fold`, `Nothing <> Just (Sum 1)` is simply `Just (Sum 1)`.
`Nothing <> Nothing` is `Nothing` and `Just (Sum 4) <> Just (Sum 3)` is `Just (Sum 7)`.
So we nicely skip the rows that don't have the mismatching property._

We get our answer and move onto part 2.

For part two we can do something very similar with two changes: what we are looking for is different and the scoring is different.

```haskell
solveb :: String -> Maybe Integer
solveb [] = Nothing
solveb (b:bs) = solve' bs [b]
    where
        solve' _ [] = Nothing
        solve' [] os = Just . autoScore . mconcat . map scoreb $ os
        solve' (b':bs') (o:os) | b' `elem` "({[<"                       = solve' bs' (b':o:os)
                               | [o,b'] `elem` ["()", "[]", "{}", "<>"] = solve' bs' os
                               | otherwise                              = Nothing
```

Like last time if we finish with `Nothing` if the row isn't of the right type and `Just` the score if we are left with unclosed brackets.

This time, if the opening brackets is empty we return nothing, but we calculate the score if the string is depleted with brackets left in the open brackets stack.
I'll go through the scoring logic later.
If both lists have elements we once again shift open brackets to the stack,
recurse on matching brackets popping the open bracket from the stack.
If it's a mismatching bracket we are in the part 1 case and so return `Nothing`.

For the scoring we need to multiply the current score by 5 and add the next score.

_N.B. This is just base 5 as the scores are 1-4._

However, as I'd just `Sum` in part 1 I wanted to try a Monoid for part 2.

```haskell
data AutocompleteScore a = (Num a) => Auto { autoScore :: a }

instance Semigroup (AutocompleteScore a) where
    (Auto s) <> (Auto s') = Auto ((s * 5) + s')

instance (Num a) => Monoid (AutocompleteScore a) where
    mempty = Auto 0
    mconcat = foldl (<>) mempty
```

It works by taking the left side of the `(<>)` multiplying by 5, then adding the right side.
The `mempty` is just `0`, and `mconcat` is a `foldl` not `foldr` like the default implementation.
_Technically, this isn't a Semigroup as it doesn't satisfy the Associativity law... but I didn't mind for this use case._

```haskell
scoreb :: Char -> AutocompleteScore Integer
scoreb = \case
    '(' -> Auto 1
    '[' -> Auto 2
    '{' -> Auto 3
    '<' -> Auto 4
    _   -> mempty
```

_N.B. We don't need to map to the closing bracket and score that like the problem states, scoring the open bracket works just as well._

Finally, we just need to pic the middle number, which is easy enough with:

```haskell
middle :: (Ord a) => [a] -> Maybe a
middle ns = sort ns !? (length ns `div` 2)

solve bs = middle . mapMaybe solveb $ bs
```

Part 2 done!


### Day 10 Benchmarks

```
>> Day 10a
benchmarking...
time                 430.3 μs   (428.7 μs .. 432.4 μs)
                     1.000 R²   (1.000 R² .. 1.000 R²)
mean                 431.3 μs   (429.8 μs .. 433.5 μs)
std dev              6.484 μs   (3.791 μs .. 9.634 μs)

* parsing and formatting times excluded

>> Day 10b
benchmarking...
time                 489.7 μs   (483.7 μs .. 501.2 μs)
                     0.996 R²   (0.990 R² .. 1.000 R²)
mean                 489.7 μs   (484.4 μs .. 501.1 μs)
std dev              24.51 μs   (11.37 μs .. 42.20 μs)
variance introduced by outliers: 44% (moderately inflated)

* parsing and formatting times excluded
```



Day 11
------

<!--
This section is generated and compiled by the build script at ./Build.hs from
the file `./reflections/day11.md`.  If you want to edit this, edit
that file instead!
-->

*[Prompt][d11p]* / *[Code][d11g]*

[d11p]: https://adventofcode.com/2021/day/11
[d11g]: https://github.com/egnwd/advent/blob/2021/src/AOC/Challenge/Day11.hs

I again enjoyed the theme on this day, I liked the idea of the flashing octopuses.

Part 1 and 2 had a nice similar foundation and just had different stopping criteria.

I'll first explain my core logic, then cover the stopping criteria.

We need a function that can take a step for all the octopuses, then we iterate this step function.
Similar to how you might solve a conways game of life problem.

To define the step function we want something that takes the octopuses and gives us a new state of octopuses:

```haskell
type Octopuses = M.Map Point Int

step :: Octopuses -> Octopuses
step os = undefined
```

The algorithm we need steps the energy level of each octopus once,
then again for each octopus next to an octopus that flashed (note that if an
octopus is adjacent to 2 octopuses that flash, it flashes twice).

It does this until it settles (octopuses can flash only once per step)
and then the flashed octopuses reset their energy.

I broke this into two stages:

1. Finding the settled state (fixed point)
1. Resetting the grid

A fixed point takes a function from some state to another state of the same time,
and keeps applying this function (starting with some initial state) until it sees the same state twice,
and returns that state.

My fixed point function takes a frequency map of octopuses to give an energy boost, and how many times to do so, and the map of octopuses.

```haskell
next :: (M.Map Point Int, Octopuses) -> (M.Map Point Int, Octopuses)
next (keys, os) = (keys', fst <$> os')
    where
        keys' = (`M.restrictKeys` M.keysSet didn'tFlash) . freqs . concatMap allNeighbours . M.keys $ flashed
        (flashed, didn'tFlash) = M.partition snd os'
        os' = M.mapWithKey (boost keys) os
```

So we first map the octopuses `os` to a new set of octopuses `os'`.
We partition this into those that flashed and those that did not.
We then find the neighbours of the octopuses that flashed,
and turn that into a frequency map of how many times a neighbour octopus appears.

We then restrict that to octopuses that didn't flash, to ensure nothing flashes twice.

Then we return the octopuses to boost next time and the new octopuses.
If there are no more octopuses to flash the octopuses are unchanged and we will see an unchanged set of octopuses twice in a row, the fixed point.

We boost the energy as follows:

```haskell
boost :: Octopuses -> Point -> Int -> (Int, Bool)
boost ks k o | k `M.member` ks && o < 10 = let o' = o + lookupFreq k ks in (o', o' > 9)
             | otherwise   = (o, False)
```

If the octopus is in the set of octopuses to boost and the octopus has not yet flashed (`< 10`) then we boost it the required number of times
returning the new energy level and if it just flashed (`> 9`).
If not, we keep the level the same and return that it didn't _just_ flash.

We can then put this into a fixed point and reset the result:

```haskell
step :: Octopuses -> Octopuses
step os = Data.Map.map reset . snd $ fixedPoint next (1 <$ os, os)
    where
        reset o = if o > 9 then 0 else o
```

Here we initialise our frequency map to boost each octopus once, and pass the initial octopus state.
Then we get the final state of the octopuses out of the fixed point and reset each octopus.

That works by setting it's energy level to `0` if it was above `9`.

That's the core logic done.

For part 1 we count the total number of flashes after 100 days:

```haskell
solvea :: Octopuses -> Int
solvea os = (!! 100) . scanl1 (+) . map (countTrue (==0)) . iterate step $ os
```

To do this we keep running the step function, and for each step count the number of `0`s in the octopuses.
`scanl1 (+)` then generates a running total for each step, and finally we get the running total of day 100.

Job done!

For part 2 we need to keep going until all the octopuses flash at the same time, and return the step it happens on:

```haskell
solveb :: Octopuses -> Int
solveb os = fst . head . dropWhile (not . all (==0) . snd) . zip [0..] . iterate step $ os
```

We run the same core logic as last time of iterating the step function on the octopuses,
we then combine each state with it's step index (`zip [0..]`).

The we ignore each state where not all the octopuses have flashed (i.e. reset to `0`).
As soon as we find one (`head`) we take the step index and return it.

Part 2 complete!


### Day 11 Benchmarks

```
>> Day 11a
benchmarking...
time                 25.97 ms   (24.84 ms .. 26.81 ms)
                     0.994 R²   (0.985 R² .. 0.998 R²)
mean                 26.48 ms   (25.99 ms .. 27.47 ms)
std dev              1.333 ms   (710.4 μs .. 2.377 ms)
variance introduced by outliers: 16% (moderately inflated)

* parsing and formatting times excluded

>> Day 11b
benchmarking...
time                 120.9 ms   (103.9 ms .. 142.3 ms)
                     0.970 R²   (0.931 R² .. 0.999 R²)
mean                 110.4 ms   (107.4 ms .. 118.4 ms)
std dev              7.722 ms   (1.700 ms .. 11.59 ms)
variance introduced by outliers: 23% (moderately inflated)

* parsing and formatting times excluded
```



Day 12
------

<!--
This section is generated and compiled by the build script at ./Build.hs from
the file `./reflections/day12.md`.  If you want to edit this, edit
that file instead!
-->

*[Prompt][d12p]* / *[Code][d12g]*

[d12p]: https://adventofcode.com/2021/day/12
[d12g]: https://github.com/egnwd/advent/blob/2021/src/AOC/Challenge/Day12.hs

Day 12 was satisfying as there is a common solution to part 1 and 2 with a tweaked condition (similar to yesterday).

For today, we have a cave network that we need to explore, so the first thing I did was parse the network into a graph.

I won't go into the full graph building logic but the essence is taking the pairs from the inputs and adding them to a graph in both directions,
except when we are coming out of the `"end"` node or into the `"start"` state. If you are curious you can see the `buildGraph` function [here](https://github.com/egnwd/advent/blob/2021/src/AOC/Challenge/Day12.hs#L38).

The important thing to note is the value at each node is if it is a LARGE cave (`True`) or a small cave (`False`).

The output from parsing is a function that takes a node and gives you it's value, key and neighbours in the graph:

```haskell
type Cave = String
type GraphNeighbours = Cave -> (Bool, Cave, [Cave])
```

Our objective is, given some cave entry condition, to find the number of possible paths through the network from `"start"` to `"end"`.

Intuitively, to do this we can follow every allowed neighbour at each node in the graph until it reaches a terminating state,
or the path is pruned because it's not allowed.

We can define a function that takes the predicate and our `getNode` function we parsed.
We keep track internally with the set of nodes to explore next and a frequency map of how many times we have entered a cave on the current path.
The code looks like:

```haskell
findPaths :: EnterCavePredicate -> GraphNeighbours -> Int
findPaths canEnterCave getNode = sum $ findPaths' empty start
    where
        start = getNode "start" ^. _3
        findPaths' _ [] = return 1
        findPaths' seen ns = do
            (large, n, ns') <- map getNode ns
            guard $ canEnterCave seen n large
            let seen' = if large then seen else alter (pure . maybe 1 succ) n seen
            findPaths' seen' ns'
```

`findPaths'` is where the main recursive logic happens,
and we can use the fact that the list is a monad to take full use of the `do` notation.

For recursive functions I always remember a phrase from my lecturer:
> Take a leap of faith

meaning, if you have correctly implemented the current iteration correctly,
you can trust yourself, take a leap of faith and call the function recursivly and get back the right result.

As with all recursive functions we have a base case:
when there are no neighbours to visit (`[]`) then we have reached the `"end"`
(as we removed the paths out of this state when parsing).
Upon terminating we return a `1` to indicate a new path.

For the recursive case we need to branch out from the next set of neighbours `ns`.
We map each neighbour to it's node and get out the `(large, n, ns')` for that node.

If you aren't familiar with `do` notation for lists it acts a little like a list comprehension:

```haskell
f = do
  n <- [1,2,3,4]
  [n*2]
```

is the same as:

```haskell
f = [n * 2 | n <- [1,2,3,4]]
```

Both result in `[2,4,6,8]` note that the return value from the `do` notation is a list,
and the result is the concatenation of those lists.

Back to `findPaths'`:

We can use a neat function from `Control.Monad`: `guard`.

It takes a boolean, which if `True` continues with the execution,
otherwise it short circuits with the `empty` case (`empty` from `Alternative`).

Not surprisingly, `empty` for a list is `[]`. This essentially prunes this branch of the exploration.

If we pass this check we update our seen frequency map (if it's a small cave as that's all we care about,
large caves can always be entered as many times as we like).

_N.B. `alter (pure . maybe 1 succ) n seen` will add to the map the node with the count `1` or if it's already in the map add one (`succ`)._

We then recurse into the neighbours of this node (remember all the neighbours of all the current set to look through will be explored, assuming they aren't pruned).

Finally, we can sum the resulting list of numbers (all 1s), this is the same as getting the length of the list and filling it with `()`.

This works for part 1 and 2, we just need to define the `canEnterCave` predicates:

```haskell
type EnterCavePredicate
    =  M.Map String Int -- ^ Cave -> Number of times visited
    -> Cave             -- ^ Cave name
    -> Bool             -- ^ True when the cave is large
    -> Bool

part1Predicate, part2Predicate :: EnterCavePredicate
part1Predicate seen a large = large || lookupFreq a seen == 0
part2Predicate seen a large = large || (\s -> s == 0 || s == 1 && all (<2) seen) (lookupFreq a seen)
```

In both cases if the cave is LARGE then we short circuit and say we can enter the cave.
For part 1, if we've not seen the cave before then we can enter.
For part 2, if we've not seen it before or we've seen it once, but not seen any other cave more than once, we can enter.

Done!


### Day 12 Benchmarks

```
>> Day 12a
benchmarking...
time                 8.572 ms   (8.524 ms .. 8.630 ms)
                     0.999 R²   (0.998 R² .. 1.000 R²)
mean                 8.585 ms   (8.552 ms .. 8.637 ms)
std dev              132.2 μs   (86.57 μs .. 206.6 μs)

* parsing and formatting times excluded

>> Day 12b
benchmarking...
time                 248.2 ms   (244.0 ms .. 251.0 ms)
                     1.000 R²   (1.000 R² .. 1.000 R²)
mean                 259.9 ms   (255.3 ms .. 266.5 ms)
std dev              7.280 ms   (4.029 ms .. 9.361 ms)
variance introduced by outliers: 16% (moderately inflated)

* parsing and formatting times excluded
```



Day 13
------

<!--
This section is generated and compiled by the build script at ./Build.hs from
the file `./reflections/day13.md`.  If you want to edit this, edit
that file instead!
-->

*[Prompt][d13p]* / *[Code][d13g]*

[d13p]: https://adventofcode.com/2021/day/13
[d13g]: https://github.com/egnwd/advent/blob/2021/src/AOC/Challenge/Day13.hs

Today was interesting, and our first time this year seeing a non-Int answer.

For our first task we need to parse the data.

I chose to represent the paper as a set of points (`Set (V2 Int)`) and the folds as a custom data type (`Fold`).

```haskell
type TransparentPaper = Set (V2 Int)
data Fold = FX Int | FY Int
```

_`V2` is from the `Linear` library and represents a vector of 2 items._

For details on the full parsing check out the code but the main idea is:
 - For a point split on the ',' and make a `V2` from the two numbers
 - Turn all the points into a set
 - For a fold, if it's `"x="` then parse the number into the `FX` constructor, else parse it into the `FY` constructor

and that's pretty much it!

So for part 1 we just need to apply the first fold and count the remaining points,
nicely alluding to what part 2 is going to be and making sure we are on the right track.

To start with I needed a function that decides if a point is beyond the fold or not.
From the problem we know that points that get moved are "greater" than the fold line.

So we can define a `beyondFold` function like so:

```haskell
beyondFold :: V2 Int -> Fold -> Bool
beyondFold (V2 x y) = \case
    FX fx -> x > fx
    FY fy -> y > fy
```

next we need to remap any points that lie beyond the fold to new positions on the folded side.

```
┌─────┐
│ #   │
│ ▲   │
├─┼───┤
│ │   │
│ #   │
└─────┘
```

in this example the **#** is being mapped to above the line `y=2`.

This results in a transformation from `(1,4)` to `(1,0)`.

More generally we can get this by, for a Y-fold, keeping `x` the same,
and then subtracting from the line (`2`) the distance from the point to the line (`4-2`).
`fy - (y - fy)` which simplifies to `2 * fy - y`.
Similar logic can be used for the X-fold, replacing `y` & `fy` for `x` & `fx`, respectively.

This gives us our remapPoint function:

```haskell
remapPoint :: Point -> Fold -> Point
remapPoint (V2 x y) = \case
    FX fx -> V2 (2*fx-x) y
    FY fy -> V2 x        (2*fy-y)
```

The only remaining thing to do is partition the points, remap the ones beyond the fold and union the remapped points with the ones that didn't move.

```haskell
applyFold :: TransparentPaper -> Fold -> TransparentPaper
applyFold points f = union remappedPoints remainingPoints
    where
        remappedPoints = map (`remapPoint` f) pointsToMove
        (pointsToMove, remainingPoints) = partition (`beyondFold` f) points
```

_You could also do this with a single `map` with an `if`, but I preferred this approach._

Finally, we just need to count the number of points after the first fold:

```haskell
solve paper (f:fs) = size $ applyFold paper f
```

Woo, part 1 done!

For part 2 we need to apply all the folds and read the string from the ASCII art.

Applying all the folds is simple, we use:

```haskell
solve paper folds = foldl applyFold paper folds
```

This results in a set of points that we can print, squint and type into the answer box.

_However, that doesn't get us the final answer..._

To do this I used the [`Advent.OCR` library](https://github.com/mstksg/advent-of-code-ocr),
which exposes a `parseLettersWith` function which takes a function for extracting the x coordinate, one for the y coordinate and a set of points.

```haskell
readCode paper = parseLettersWith (view _x) (view _y) paper
```

Now we are ready to do some thermal imaging!


### Day 13 Benchmarks

```
>> Day 13a
benchmarking...
time                 9.140 ms   (8.989 ms .. 9.345 ms)
                     0.997 R²   (0.994 R² .. 0.998 R²)
mean                 9.202 ms   (9.044 ms .. 9.348 ms)
std dev              409.6 μs   (306.2 μs .. 579.2 μs)
variance introduced by outliers: 18% (moderately inflated)

>> Day 13b
benchmarking...
time                 6.140 ms   (5.671 ms .. 6.795 ms)
                     0.957 R²   (0.915 R² .. 0.998 R²)
mean                 5.750 ms   (5.637 ms .. 6.009 ms)
std dev              507.0 μs   (187.8 μs .. 935.5 μs)
variance introduced by outliers: 54% (severely inflated)
```



Day 14
------

<!--
This section is generated and compiled by the build script at ./Build.hs from
the file `./reflections/day14.md`.  If you want to edit this, edit
that file instead!
-->

*[Prompt][d14p]* / *[Code][d14g]*

[d14p]: https://adventofcode.com/2021/day/14
[d14g]: https://github.com/egnwd/advent/blob/2021/src/AOC/Challenge/Day14.hs

Another growth issue to contend with, but we can solve it in a similar manner to the lanternfish,
keeping track of a frequency map of states to reduce the number of operations we need to perform.

Luckily part 1 & 2 have common solution.

First let's set up the skeleton of the process, we need to input a formula and get the range of frequencies out.

```haskell
type Element = Char

formulaFrequencies :: Map (Element, Element) Int -> Map Element Int
formulaFrequencies = M.mapKeysWith (+) snd

scoreFormula :: (Num n, Ord n) => Map a n -> Maybe n
scoreFormula f
  = case (maximumOf traverse f, minimumOf traverse f) of
    (Just mx, Just mn) -> Just (mx - mn)
    _                    -> Nothing

solve :: Int -> (String, Map (Element, Element) Element) -> Maybe Int
solve n = scoreFormula . formulaFrequencies <=< uncurry (generateFormula n)
```

`generateFormula` will take an initial formula and give back a map of element pair frequencies after `n` steps.
`formulaFrequencies` take the steps and returns just the second element from each pair.
This is to avoid repeated counts for the elements.
_I'm pretty sure this nly works because the initial letter of my input formular is neither the minimum or maximum, but oh well._

`scoreFormula` then gets the range of the frequencies, assuming they exist.

The core then happens in `generateFormula`.

We iterate a substituion step n times and return the final frequencies.

```haskell
generateFormula :: Int -> String -> FormulaMapping -> Maybe (FormulaFrequencies (Element, Element))
generateFormula n formula m = (!? n) . iterate substitute $ formula'
    where
        formula' = freqs . pairwise $ formula
        pairwise ls = zip ls (tail ls)
        substitute = M.fromListWith (+) . foldMap (\(k,a) -> map (,a) . new $ k) . M.toList
        new k@(a,b) = case M.lookup k m of { Just c -> [(a,c), (c,b)]; Nothing -> [k] }
```

The `substitute` step takes each pair and runs a substituion phase which produces up to 2 pairs,
for example given the pair `(NV, 4)` and the substituion `NV -> C` we get `[(NC, 4), (CV, 4)]`.

We then roll up the frequencies into another frequency map.

`n` steps later and we have the answer!


### Day 14 Benchmarks

```
>> Day 14a
benchmarking...
time                 370.5 μs   (369.6 μs .. 371.4 μs)
                     1.000 R²   (1.000 R² .. 1.000 R²)
mean                 370.8 μs   (369.8 μs .. 372.0 μs)
std dev              3.501 μs   (2.784 μs .. 4.635 μs)

* parsing and formatting times excluded

>> Day 14b
benchmarking...
time                 2.060 ms   (2.051 ms .. 2.070 ms)
                     1.000 R²   (1.000 R² .. 1.000 R²)
mean                 2.057 ms   (2.050 ms .. 2.067 ms)
std dev              29.20 μs   (18.66 μs .. 43.78 μs)

* parsing and formatting times excluded
```



Day 15
------

<!--
This section is generated and compiled by the build script at ./Build.hs from
the file `./reflections/day15.md`.  If you want to edit this, edit
that file instead!
-->

*[Prompt][d15p]* / *[Code][d15g]*

[d15p]: https://adventofcode.com/2021/day/15
[d15g]: https://github.com/egnwd/advent/blob/2021/src/AOC/Challenge/Day15.hs

Today was an execellent [A* problem](https://en.wikipedia.org/wiki/A*_search_algorithm), we start at the origin and aim for the bottom right corner.
The cost to travel is the risk, and the hueristic is the manhattan distance to the corner.


### Day 15 Benchmarks

```
>> Day 15a
benchmarking...
time                 141.6 ms   (136.9 ms .. 153.1 ms)
                     0.996 R²   (0.989 R² .. 1.000 R²)
mean                 140.6 ms   (138.0 ms .. 144.1 ms)
std dev              4.223 ms   (2.523 ms .. 6.021 ms)
variance introduced by outliers: 12% (moderately inflated)

* parsing and formatting times excluded

>> Day 15b
benchmarking...
time                 5.281 s    (5.078 s .. 5.542 s)
                     1.000 R²   (0.999 R² .. 1.000 R²)
mean                 4.936 s    (4.708 s .. 5.104 s)
std dev              217.7 ms   (4.221 ms .. 266.1 ms)
variance introduced by outliers: 19% (moderately inflated)

* parsing and formatting times excluded
```



Day 16
------

<!--
This section is generated and compiled by the build script at ./Build.hs from
the file `./reflections/day16.md`.  If you want to edit this, edit
that file instead!
-->

*[Prompt][d16p]* / *[Code][d16g]*

[d16p]: https://adventofcode.com/2021/day/16
[d16g]: https://github.com/egnwd/advent/blob/2021/src/AOC/Challenge/Day16.hs

Today was a fun task for parsing.

Firstly we can define some types to help us represent a packet.

```haskell
data Packet
    = Literal Int Integer
    | Operator Int Operator [Packet]

data Operator
    = OpSum
    | OpProd
    | OpMin
    | OpMax
    | OpGT
    | OpLT
    | OpEQ
```

A packet can either be a literal or an operator.
A literal takes a version number and value.
An operator takes a version number, an operator and a list of sum packets.

The operator sum type is one of `sum`, `product`, `minimum`, `maximum`, `greater than`, `less than` and `equal`.

```haskell
parsePacket :: CharParser Packet
parsePacket = do
    v   <- toBinOrZero <$> takeP (Just "Version") 3
    typ <- toOp . toBinOrZero =<< takeP (Just "Operator") 3
    case typ of
      Nothing -> Literal v <$> parseLiteral
      Just op -> Operator v op <$> parseOperator

toBinOrZero :: (Integral a) => String -> a
toBinOrZero = fromMaybe 0 . preview binary

toOp :: Int -> CharParser (Maybe Operator)
toOp = \case
    0 -> pure $ Just OpSum
    1 -> pure $ Just OpProd
    2 -> pure $ Just OpMin
    3 -> pure $ Just OpMax
    4 -> pure   Nothing
    5 -> pure $ Just OpGT
    6 -> pure $ Just OpLT
    7 -> pure $ Just OpEQ
    n -> failure (Tokens <$> NE.nonEmpty (show n)) (S.singleton (Tokens . NE.fromList $ "Packet Type (0-7)"))
```

The top level parsing function takes the first 3 numbers and parses them as a binary number using `Numeric.Lens` which will read a binary number to a number.

Then the next 3 numbers are the operator type, which is either `Just` an operator or `Nothing` if it's a literal.
We then either parse a literal or operator into it's constructor with the version number.

To parse a literal we take chunks of 5 bits, consume the bits and either finish if the flag is `0` or parse another 5 if the flag is `1`.

```haskell
parseLiteral :: CharParser Integer
parseLiteral = toBinOrZero <$> parseLiteral'
    where
        parseLiteral' :: CharParser String
        parseLiteral' = do
            f <- anySingle
            d <- takeP (Just "Literal") 4
            rest <- if f == '0' then pure [] else parseLiteral'
            pure (d++rest)
```

To parse an operator we either parse an 11 bits and then parse just as many packets, or parse the next 15 bits as a length and parse the rest as a set of packets.

```haskell
parseOperator :: CharParser [Packet]
parseOperator = (char '0' *> parse15Operator) <|> (char '1' *> parse11Operator)
    where
        parse15Operator = do
            len <- takeP (Just "Length of subpackets") 15
            parseOrFail (many parsePacket) <$> takeP (Just "subpackets") (toBinOrZero len)
        parse11Operator = do
            cnt <- takeP (Just "Count of subpackets") 11
            count (toBinOrZero cnt) parsePacket
```

For the solving I used a [catamorphism](https://blog.sumtypeofway.com/posts/recursion-schemes-part-2.html).
This takes a recursive structure and folds it into a result. Some examples of _catamorphisms_ are: `length` or `sum`.
Catamorphisms are `foldr` generalised to any Functor.

For part 1 we need to count the version numbers:

```haskell
getVersionSum :: PacketF Int -> Int
getVersionSum (LiteralF v _) = v
getVersionSum (OperatorF v _ ps) = v + sum ps
```

`PacketF` is a autogenerated base functor for the `Packet` type.
If we encounter a literal then we return the version number.
If we encounter an operator, we take it's version number and add the sum of all the sub version numbers.
Notice here there is no recursive call,
the _catamorphism_ has taken care of this and the `ps` variable will already be the version sum of each sub-packet.
_Notice that the structure is a [Rose Tree](https://en.wikipedia.org/wiki/Rose_tree)._

For part 2 we need to apply all the operations and calculate the packet, again we use a _catamorphism_.

```haskell
calculate :: PacketF Integer -> Integer
calculate (LiteralF _ l)     = l
calculate (OperatorF _ OpSum ps)   = sum ps
calculate (OperatorF _ OpProd ps)  = product ps
calculate (OperatorF _ OpMin ps)   = minimum ps
calculate (OperatorF _ OpMax ps)   = maximum ps
calculate (OperatorF _ OpGT [a,b]) | a > b  = 1
calculate (OperatorF _ OpLT [a,b]) | a < b  = 1
calculate (OperatorF _ OpEQ [a,b]) | a == b = 1
calculate _                        = 0
```

In this case, when we reach a literal, we simply return it's value.
For the recursive case we are given the `Integer` value of each sub packet,
so we just need to apply the operation.

_Note, for this problem we cound have mapped the operator types directly to the operator functions, e.g. `0 -> sum`.
However I decided to add hte intermediate type in case we wanted to do things like print the tree of packets etc._

And that's it! a super easy definition thanks to the recursive nature of hte rose tree.


### Day 16 Benchmarks

```
>> Day 16a
benchmarking...
time                 6.333 ms   (5.723 ms .. 7.255 ms)
                     0.923 R²   (0.887 R² .. 0.971 R²)
mean                 6.180 ms   (5.875 ms .. 6.494 ms)
std dev              1.023 ms   (807.2 μs .. 1.287 ms)
variance introduced by outliers: 80% (severely inflated)

>> Day 16b
benchmarking...
time                 4.776 ms   (4.175 ms .. 5.842 ms)
                     0.740 R²   (0.623 R² .. 0.865 R²)
mean                 5.463 ms   (4.979 ms .. 6.146 ms)
std dev              1.895 ms   (1.401 ms .. 2.578 ms)
variance introduced by outliers: 97% (severely inflated)
```



Day 17
------

<!--
This section is generated and compiled by the build script at ./Build.hs from
the file `./reflections/day17.md`.  If you want to edit this, edit
that file instead!
-->

*[Prompt][d17p]* / *[Code][d17g]*

[d17p]: https://adventofcode.com/2021/day/17
[d17g]: https://github.com/egnwd/advent/blob/2021/src/AOC/Challenge/Day17.hs

My day 17 is not the fastest thing in the world, but it's a fairly neat and readable solution this time.

Parsing the problem is quite nice, and we can take advantage of `V2` again and it's nice Distributive properties.
`Linear` exposes this as the `transpose` function.

```haskell
type Region = V2 (V2 Int)

parser :: CharParser Region
parser = transpose <$> (V2 <$> ("target area: " *> "x=" *> parseRange <* ", ") <*> ("y=" *> parseRange))
    where
        parseRange = V2 <$> pDecimal <*> (".." *> pDecimal)
```

We parse the x range into a `V2` and the y range into a `V2`, then transpose the little matrix:
For example: given `target area: x=0..100, y=10..60` we parse it into `V2 (V2 0 100) (V2 10 60)`,
then `transpose` gives us `V2 (V2 0 10) (V2 100 60)`, i.e. the minimum corner and the maximum corner of the target area.

**Part 1:**

For part 1 we can simulate various paths for the trajectories, up until we have gone past the target area.
After that we can check if it's a valid trajectory if it is in the bounding box.
From the trajectories that remain we can find the maximum Y displacement.

Let's first start by defining a function that checks if a point is past a bounding box.

```haskell
pastBoundingBox
    :: (Integral a)
    => V2 (V2 a) -- Bounding Box
    -> V2 a      -- Point to check
    -> Bool
pastBoundingBox b p = or $ go <$> p <*> maxB
  where
    V2 xs ys = transpose b
    maxB = floor <$> maximumBy (dist @Double) [V2 (fromIntegral x) (fromIntegral y) | x <- toList xs, y <- toList ys]
    dist :: forall a. (Floating a, Ord a) => V2 a -> V2 a -> Ordering
    dist = compare `on` distanceA zero
    go x' mx' = if mx' < 0 then x' < mx' else x' > mx'
```

`maxB` finds the corner furthest from the origin, we then compare the coordinates of the target point to the calculated maximum point, and if either coordinate is larger (or smaller if negative) then we return that it's past the bounding box.

Next we need some functions to calculate the points on a trajectory path:

```haskell
type Point = V2 Int
type Velocity = V2 Int

positions :: Point -> Velocity -> [Point]
positions p0 = scanl (+) p0 . velocities

velocities :: Velocity -> [Velocity]
velocities = iterate ((_x %~ dragX) . (_y %~ dragY))
    where
        dragX vx = vx - signum vx
        dragY vy = vy - 1
```

`velocities` takes a starting velocity and returns all the decaying velocities by iterating a decay function.
First we decay the `y` component of the velocity, by deducting 1. Then we decay the `x` component by moving it 1 towards 0,
this is the same as deducting the sign of the velocity from the velocity (_note `signum` returns `1` for positive numbers, `-1` for negative numbers, and `0` for `0`_).

`positions` simply uses `scanl` to get a running cumulative sum of the velocities starting from some origin `p0`.

We then truncate the trajectory when we get past the target region, starting from (0,0).

```haskell
trajectory :: Region -> Velocity -> [Point]
trajectory targ = takeWhile (not . pastBoundingBox targ) . positions zero
```

Next we define a function that find's if a point is in the target region:

```haskell
findCollision :: Region -> [Point] -> Maybe Point
findCollision targ = find (inBoundingBox targ)
```

The last thing we need to do for part 1 is put all this together to find the maximum point.

```haskell
highestY :: Region -> Int
highestY targ
  = getMax
  . fold
  . mapMaybe ((\t -> findMaxHeight t <$ findCollision targ t) . trajectory targ)
  . filter ((>0) . view _x)
  $ validRange targ
    where
        findMaxHeight = foldMap (Max . view _y)
```

We generate a valid range of starting velocites, just to limit the search space.
For each starting velocity we generate the trajectory, attempt to find a collision,
and if we do the the max height of the trajectory `t`.
_`b <$ fa` is the same as `const a <$> fa`, where `<$>` is just infix `fmap`._

The final `fold` finds the `Max` of all the `Maxes`.

Part 1 done, and the trick shot looked pretty cool.

For part 2 we need to find all options.

Given all our helper functions, we have a very easy mechanism to do this:

```haskell
numberVelocities :: Region -> Int
numberVelocities targ = length . mapMaybe (findCollision targ . trajectory targ) $ validRange targ
```

We just omit calculating the max height and count the number of valid collisions we find.

Part 2 done!


### Day 17 Benchmarks

```
>> Day 17a
benchmarking...
time                 396.7 ms   (350.5 ms .. 444.6 ms)
                     0.997 R²   (0.997 R² .. 1.000 R²)
mean                 415.6 ms   (404.4 ms .. 423.7 ms)
std dev              11.62 ms   (5.644 ms .. 16.26 ms)
variance introduced by outliers: 19% (moderately inflated)

* parsing and formatting times excluded

>> Day 17b
benchmarking...
time                 319.2 ms   (254.2 ms .. 391.5 ms)
                     0.991 R²   (0.990 R² .. 1.000 R²)
mean                 413.6 ms   (370.0 ms .. 492.9 ms)
std dev              76.42 ms   (3.305 ms .. 93.54 ms)
variance introduced by outliers: 47% (moderately inflated)

* parsing and formatting times excluded
```



Day 18
------

<!--
This section is generated and compiled by the build script at ./Build.hs from
the file `./reflections/day18.md`.  If you want to edit this, edit
that file instead!
-->

*[Prompt][d18p]* / *[Code][d18g]*

[d18p]: https://adventofcode.com/2021/day/18
[d18g]: https://github.com/egnwd/advent/blob/2021/src/AOC/Challenge/Day18.hs

I really enjoyed day 18, despite the difficulty ramping up.
We got to define some nice infix operators too!

First let's define some types to represent our snail numbers and operations that we need to perform.

```haskell
data SnailNum = SN Int | SP SnailNum SnailNum deriving (Eq)
data Todo = NoWork | PlaceLeft Int | PlaceRight Int
```

A snail number is either a number, or a pair of snail numbers.
_A.k.a. a binary tree with only values at the leaves._

`Todo` represents work that will need to be done on the snail numbers whilst exploding them.

Let's start by defining the `explode` and `split` functions that are used when reducing the snail numbers.

```haskell
explode, split :: SnailNum -> Maybe SnailNum
```

Both take a `SnailNum` and maybe return a `SnailNum` if the explode, or split, are applicable.

Split has a simpler definition so we will start with that.

```haskell
split :: SnailNum -> Maybe SnailNum
split = histo go
    where
        go :: SnailNumF (Cofree SnailNumF (Maybe SnailNum)) -> Maybe SnailNum
        go (SNF n) = do
            guard $ n >= 10
            let n' = (fromIntegral n / 2) :: Double
            pure $ SN (floor n') `SP` SN (ceiling n')
        go (SPF l r) = asum [(`SP` out r) <$> extract l, SP (out l) <$> extract r]
```

That's the full definition, but before we approach what it means we need to understand [_histomorphisms_](https://blog.sumtypeofway.com/posts/recursion-schemes-part-4.html).
A histomorphism is similar to a _catamorphism_ or _paramorphism_, but it gives us access to the full _history_ of the computations.
It does this through the use of `Cofree`, which is defined by:

```haskell
data Cofree f a = a :< f (Cofree f a)
```

but what does this mean, well we have a recursive type that is a pair of an `a` and a `f (Cofree f a)`.
`a` acts as an _annotation_ for the current level, and the `f` is a functor of `Cofree f a`.

As part of the `Comonad` (A `Comonad` is a `Cofree Comonad` for `f` if [everfsdf d as asehfb hdfsdfjab asdfhb](https://hackage.haskell.org/package/free-5.1.7/docs/Control-Comonad-Cofree.html)*) definition we also get the function `extract`.

_* I prefer the more intuitive:_

> cofree comonads are quite useful for annotating syntax trees, or talking about streams

Anyway, back to `extract`, it allows us to _extract_ the `a` from a Comonad `w a`.
_Fun fact: we use `w` for Comonad as it's an upside down `m` that is used for Monad._

Let's looks at the base case:
A snail number splits if it is a number value and it's greater than or equal to 10.
It becomes a pair of the number split in half (with the second number taking any extra).

```haskell
go (SNF n) = do
    guard $ n >= 10
    let n' = (fromIntegral n / 2) :: Double
    pure $ SN (floor n') `SP` SN (ceiling n')
```

The guard takes care of the `>= 10` condition, if it fails we return `Nothing` (indicating no split occured).
Otherwise we return a pair with the number split in 2, the first rounded down, the second rounded up.

The recursive case is where we look at the `Cofree`:

```haskell
go (SPF l r) = asum [(`SP` out r) <$> extract l, SP (out l) <$> extract r]
```

`l` and `r` are both Cofree, using `SnailNumF` as the recursive functor, and a maybe snail number as the annotation.
We use `asum` to choose the first branch that split a snail number, if any.
`extract` takes out the annotation, i.e. the maybe split snail number, and `out` takes the recursive structure and and projects it to the snail number.

```haskell
out :: Cofree SnailNumF a -> SnailNum
out (_ :< SNF n) = SN n
out (_ :< SPF l r) = SP (out l) (out r)
```

_There might be a better way of doing this._

Next we can do `explode` in a similar manner:

```haskell
explode :: SnailNum -> Maybe SnailNum
explode inN = snd <$> histo go inN 0
    where
        go :: SnailNumF (Cofree SnailNumF (Int -> Maybe (Todo, SnailNum)))
           -> Int -> Maybe (Todo, SnailNum)
        go (SNF _) _ = Nothing
        go (SPF (nl :@: nr) r) 3 = Just (PlaceLeft nl, SP (SN 0) (nr ^@+ out r))
        go (SPF l (nl :@: nr)) 3 = Just (PlaceRight nr, SP (nl @+^ out l) (SN 0))
        go (SPF l r) d = asum $ zipWith (\f sn -> f <$> extract sn (d+1)) [explodeLeft, explodeRight] [l,r]
              where
                explodeLeft (PlaceRight nr, sn) = (NoWork, SP sn (nr ^@+ out r))
                explodeLeft (todo, sn) = (todo, SP sn (out r))

                explodeRight (PlaceLeft nl, sn) = (NoWork, SP (nl @+^ out l) sn)
                explodeRight (todo, sn) = (todo, SP (out l) sn)
```

However this time the annotation is a function that takes a depth and returns a `Maybe (Todo, SnailNum)`.

The base cases are as follows:

```haskell
go (SNF _) _ = Nothing
```

A normal number has no work to do and doesn't need exploding, so we return nothing.

```haskell
go (SPF (nl :@: nr) r) 3 = Just (PlaceLeft nl, SP (SN 0) (nr ^@+ out r))
```

If at depth 3 (starting from 0) we see a pair of ordinary numbers at the next layer,
we have work to do, we need to tell the layer above us to add the left number in it's rightmost leaf (`PlaceLeft nl`)
and the number becomes a pair of `[0,nl ^@+ out r]`. where `^@+` adding a number to the leftmost leaf of the right snail number.
i.e. `[[nl,nr],r]` becomes `Just (PlaceLeft nl, [0, nr+r])` (assuming `r` is just a number).

```haskell
go (SPF l (nl :@: nr)) 3 = Just (PlaceRight nr, SP (nl @+^ out l) (SN 0))
```

This case is the same before the but operating on the right branch first.
_N.B. we must be sure to match on the left branch first as to obey the left to right ordering of the explode operation._

Finally, the recursive case:

```haskell
go (SPF l r) d = asum [explodeLeft <$> extract l (d+1), explodeRight <$> extract r (d+1)]
      where
        explodeLeft (PlaceRight nr, sn) = (NoWork, SP sn (nr ^@+ out r))
        explodeLeft (todo, sn) = (todo, SP sn (out r))

        explodeRight (PlaceLeft nl, sn) = (NoWork, SP (nl @+^ out l) sn)
        explodeRight (todo, sn) = (todo, SP (out l) sn)
```

similar to before, we find the first branch, if any that explodes a number.
We do this by getting the annotation and passing down the next depth.

If we successfully explode the left branch we apply `explodeLeft` which looks for an `PlaceRight` command and will perform the insertion,
returning the fact there is no more work to do.

Similar logic applies if we match on the right branch.

From here we just need to define snail addition `(@+)`:

```haskell
(@+) :: SnailNum -> SnailNum -> SnailNum
a @+ b = applySnailRules (SP a b)
    where
        applySnailRules n = maybe n applySnailRules (asum [explode n, split n])
```

We make a pair of the numbers and repeatedly apply the explode and split rules until neither apply, returning the final reduced number.

The part 1 solution is to find the number after adding all the numbers, and get it's magnitude.

The magnitude can be defined by defining a _catamorphism_ over the snail number.

```haskell
magnitude :: SnailNum -> Int
magnitude = cata go
    where
        go (SNF n) = n
        go (SPF l r) = (3 * l) + (2 * r)
```

```haskell
solvea sn = magnitude (foldl1 (@+) sn)
```

Part 2 then uses a lot of what we defined for part 1, but looks for the maximum magnitude of any pair:

```haskell
solveb :: [SnailNum] -> Int
solveb ns = getMax . foldMap (Max . magnitude) $ do
    (x:ys) <- tails ns
    y <- ys
    [x @+ y, y @+ x]
```


### Day 18 Benchmarks

```
>> Day 18a
benchmarking...
time                 197.0 ms   (39.59 ms .. 422.4 ms)
                     0.873 R²   (0.744 R² .. 1.000 R²)
mean                 413.0 ms   (305.6 ms .. 511.0 ms)
std dev              116.7 ms   (82.00 ms .. 141.2 ms)
variance introduced by outliers: 72% (severely inflated)

>> Day 18b
benchmarking...
time                 3.349 s    (3.255 s .. 3.440 s)
                     1.000 R²   (1.000 R² .. 1.000 R²)
mean                 3.483 s    (3.421 s .. 3.595 s)
std dev              107.8 ms   (3.432 ms .. 129.1 ms)
variance introduced by outliers: 19% (moderately inflated)
```



Day 19
------

<!--
This section is generated and compiled by the build script at ./Build.hs from
the file `./reflections/day19.md`.  If you want to edit this, edit
that file instead!
-->

*[Prompt][d19p]* / *[Code][d19g]*

[d19p]: https://adventofcode.com/2021/day/19
[d19g]: https://github.com/egnwd/advent/blob/2021/src/AOC/Challenge/Day19.hs

*Reflection not yet written -- please check back later!*

### Day 19 Benchmarks

```
>> Day 19a
benchmarking...
time                 12.51 s    (11.05 s .. 15.13 s)
                     0.995 R²   (0.988 R² .. 1.000 R²)
mean                 11.71 s    (11.43 s .. 12.12 s)
std dev              442.7 ms   (7.884 ms .. 542.2 ms)
variance introduced by outliers: 19% (moderately inflated)

* parsing and formatting times excluded

>> Day 19b
benchmarking...
time                 12.13 s    (9.878 s .. NaN s)
                     0.995 R²   (0.983 R² .. 1.000 R²)
mean                 11.71 s    (11.36 s .. 12.12 s)
std dev              477.2 ms   (5.576 ms .. 586.7 ms)
variance introduced by outliers: 19% (moderately inflated)

* parsing and formatting times excluded
```



Day 20
------

<!--
This section is generated and compiled by the build script at ./Build.hs from
the file `./reflections/day20.md`.  If you want to edit this, edit
that file instead!
-->

*[Prompt][d20p]* / *[Code][d20g]*

[d20p]: https://adventofcode.com/2021/day/20
[d20g]: https://github.com/egnwd/advent/blob/2021/src/AOC/Challenge/Day20.hs

*Reflection not yet written -- please check back later!*

### Day 20 Benchmarks

```
>> Day 20a
benchmarking...
time                 113.8 ms   (111.3 ms .. 116.0 ms)
                     0.999 R²   (0.997 R² .. 1.000 R²)
mean                 109.7 ms   (106.6 ms .. 111.6 ms)
std dev              3.761 ms   (1.931 ms .. 4.625 ms)
variance introduced by outliers: 11% (moderately inflated)

>> Day 20b
benchmarking...
time                 2.699 s    (2.641 s .. 2.812 s)
                     1.000 R²   (1.000 R² .. 1.000 R²)
mean                 2.763 s    (2.730 s .. 2.785 s)
std dev              32.92 ms   (13.60 ms .. 42.60 ms)
variance introduced by outliers: 19% (moderately inflated)
```



Day 21
------

<!--
This section is generated and compiled by the build script at ./Build.hs from
the file `./reflections/day21.md`.  If you want to edit this, edit
that file instead!
-->

*[Prompt][d21p]* / *[Code][d21g]*

[d21p]: https://adventofcode.com/2021/day/21
[d21g]: https://github.com/egnwd/advent/blob/2021/src/AOC/Challenge/Day21.hs

*Reflection not yet written -- please check back later!*

### Day 21 Benchmarks

```
>> Day 21a
benchmarking...
time                 15.10 μs   (15.04 μs .. 15.16 μs)
                     1.000 R²   (1.000 R² .. 1.000 R²)
mean                 15.08 μs   (15.03 μs .. 15.13 μs)
std dev              174.6 ns   (144.7 ns .. 215.4 ns)

* parsing and formatting times excluded

>> Day 21b
benchmarking...
time                 1.036 s    (972.6 ms .. 1.076 s)
                     1.000 R²   (0.999 R² .. 1.000 R²)
mean                 1.031 s    (1.023 s .. 1.042 s)
std dev              11.73 ms   (4.875 ms .. 16.32 ms)
variance introduced by outliers: 19% (moderately inflated)

* parsing and formatting times excluded
```



Day 22
------

<!--
This section is generated and compiled by the build script at ./Build.hs from
the file `./reflections/day22.md`.  If you want to edit this, edit
that file instead!
-->

*[Prompt][d22p]* / *[Code][d22g]*

[d22p]: https://adventofcode.com/2021/day/22
[d22g]: https://github.com/egnwd/advent/blob/2021/src/AOC/Challenge/Day22.hs

*Reflection not yet written -- please check back later!*

### Day 22 Benchmarks

```
>> Day 22a
benchmarking...
time                 11.00 ms   (10.81 ms .. 11.17 ms)
                     0.998 R²   (0.997 R² .. 0.999 R²)
mean                 11.01 ms   (10.85 ms .. 11.14 ms)
std dev              423.8 μs   (299.7 μs .. 618.8 μs)
variance introduced by outliers: 16% (moderately inflated)

>> Day 22b
benchmarking...
time                 328.2 ms   (322.2 ms .. 330.5 ms)
                     1.000 R²   (1.000 R² .. 1.000 R²)
mean                 328.8 ms   (327.3 ms .. 329.7 ms)
std dev              1.504 ms   (944.6 μs .. 2.174 ms)
variance introduced by outliers: 16% (moderately inflated)
```

Day 23
------

<!--
This section is generated and compiled by the build script at ./Build.hs from
the file `./reflections/day23.md`.  If you want to edit this, edit
that file instead!
-->

*[Prompt][d23p]* / *[Code][d23g]*

[d23p]: https://adventofcode.com/2021/day/23
[d23g]: https://github.com/egnwd/advent/blob/2021/src/AOC/Challenge/Day23.hs

*Reflection not yet written -- please check back later!*

### Day 23 Benchmarks

*Not benchmarked yet -- please check back later!*


Day 24
------

<!--
This section is generated and compiled by the build script at ./Build.hs from
the file `./reflections/day24.md`.  If you want to edit this, edit
that file instead!
-->

*[Prompt][d24p]* / *[Code][d24g]*

[d24p]: https://adventofcode.com/2021/day/24
[d24g]: https://github.com/egnwd/advent/blob/2021/src/AOC/Challenge/Day24.hs

*Reflection not yet written -- please check back later!*

### Day 24 Benchmarks

```
>> Day 24a
benchmarking...
time                 20.65 ns   (20.58 ns .. 20.73 ns)
                     1.000 R²   (1.000 R² .. 1.000 R²)
mean                 20.73 ns   (20.65 ns .. 20.84 ns)
std dev              300.0 ps   (237.2 ps .. 383.7 ps)
variance introduced by outliers: 18% (moderately inflated)

* parsing and formatting times excluded

>> Day 24b
benchmarking...
time                 20.67 ns   (20.60 ns .. 20.78 ns)
                     1.000 R²   (1.000 R² .. 1.000 R²)
mean                 20.65 ns   (20.60 ns .. 20.73 ns)
std dev              216.2 ps   (169.5 ps .. 291.3 ps)
variance introduced by outliers: 10% (moderately inflated)

* parsing and formatting times excluded
```



Day 25
------

<!--
This section is generated and compiled by the build script at ./Build.hs from
the file `./reflections/day25.md`.  If you want to edit this, edit
that file instead!
-->

*[Prompt][d25p]* / *[Code][d25g]*

[d25p]: https://adventofcode.com/2021/day/25
[d25g]: https://github.com/egnwd/advent/blob/2021/src/AOC/Challenge/Day25.hs

Christmas Day!

Another iteration based approach, just needing the index of the fixed point.

Let's start by defining a stepping function for the sea cucumbers.

```haskell
step :: Point -> Map Point Dir -> Map Point Dir
step bounds = stepDir South . stepDir East
    where
        stepDir :: Dir -> Map Point Dir -> Map Point Dir
        stepDir dir mp = mapKeys moveCuke mp
            where
                dirs = keysSet . filter (==dir) $ mp
                moveCuke p = let p' = mod <$> p + dirVec dir <*> bounds
                                 isDir = member p dirs
                              in if isDir && p' `M.notMember` mp then p' else p
```

We define the landscape of sea cucumbers as a map from it's location to which direction it's facing.
To step the cucumbers we first move all the East pointing cucumbers, then the south facing ones.
And so to step the cucumbers in a direction we map all the locations to a new location,
if the cucumber isn't facing in the direction of interest we don't move it, if it is in the direction of interest,
and there is no cucumber in the new location, we set it's location to the new location.
We calculate the new location by adding the direction vector to the original point and taking that modulo the bounds of the map.
_N.B. East -> `V2 1 0` and South -> `V2 0 1`_

We then just need to find the fixed point:

```haskell
solve mp = go 1 mp
  where
    go idx !x
        | x == y    = idx
        | otherwise = go (idx+1) y
      where
        y = step (findMax mp) x
```

Christmas saved! Merry Christmas!!


### Day 25 Benchmarks

```
>> Day 25a
benchmarking...
time                 14.19 s    (14.03 s .. 14.32 s)
                     1.000 R²   (1.000 R² .. 1.000 R²)
mean                 14.17 s    (14.13 s .. 14.19 s)
std dev              36.83 ms   (17.89 ms .. 51.73 ms)
variance introduced by outliers: 19% (moderately inflated)

* parsing and formatting times excluded

>> Day 25b
benchmarking...
time                 76.44 ns   (76.16 ns .. 76.78 ns)
                     1.000 R²   (1.000 R² .. 1.000 R²)
mean                 76.55 ns   (76.32 ns .. 76.87 ns)
std dev              887.2 ps   (686.2 ps .. 1.196 ns)
variance introduced by outliers: 11% (moderately inflated)

* parsing and formatting times excluded
```

