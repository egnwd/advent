Reflections
===========

<!--
This file generated by the build script at ./Build.hs from the files in
./reflections.  If you want to edit this, edit those instead!
-->

Table of Contents
-----------------

* [Day 1](#day-1)
* [Day 2](#day-2)
* [Day 3](#day-3)
* [Day 4](#day-4)
* [Day 5](#day-5)
* [Day 6](#day-6)
* [Day 7](#day-7)
* [Day 8](#day-8) *(no reflection yet)*
* [Day 9](#day-9)
* [Day 10](#day-10) *(no reflection yet)*

Day 1
------

<!--
This section is generated and compiled by the build script at ./Build.hs from
the file `./reflections/day01.md`.  If you want to edit this, edit
that file instead!
-->

*[Prompt][d01p]* / *[Code][d01g]*

[d01p]: https://adventofcode.com/2021/day/1
[d01g]: https://github.com/egnwd/advent/blob/2021/src/AOC/Challenge/Day01.hs

Reading a list of ints always seems to be early on, we can do that easily with:

```haskell
parser = map read . lines
```

Then for part 1 we need to get the differences, which can be achieved by dropping the head of the
list then subtracting the two lists element-wise:

```haskell
differences x = zipWith subtract x (tail x)
```

_N.B. `subtract` is just `-` with the arguments flipped, useful for partial application._

and then to get the answer we need only the increases we just filter for where we got a postitive result:

```haskell
part1 = length . filter (>0) . differences
```

Yay! 1 star!

For part 2 we can reuse the differences logic from part 1, we just need to construct a new input list using the windows.
The easiest way to do this given the window is only length 3 is use the version of `zipWith` that takes 3 lists, this time with addition.

```haskell
summedSlidingWindows x = zipWith3 (\a b c -> a + b + c) x (drop 1 x) (drop 2 x)
```

Then to solve we just use part 1.

```haskell
part2 = part1 . summedSlidingWindows
```

Day 1 complete!


### Day 1 Benchmarks

```
>> Day 01a
benchmarking...
time                 47.27 μs   (46.45 μs .. 48.43 μs)
                     0.994 R²   (0.990 R² .. 0.997 R²)
mean                 47.09 μs   (45.79 μs .. 48.64 μs)
std dev              4.412 μs   (3.534 μs .. 5.703 μs)
variance introduced by outliers: 82% (severely inflated)

* parsing and formatting times excluded

>> Day 01b
benchmarking...
time                 208.5 μs   (202.4 μs .. 214.6 μs)
                     0.994 R²   (0.990 R² .. 0.997 R²)
mean                 210.7 μs   (206.9 μs .. 216.4 μs)
std dev              15.33 μs   (10.99 μs .. 20.72 μs)
variance introduced by outliers: 67% (severely inflated)

* parsing and formatting times excluded
```



Day 2
------

<!--
This section is generated and compiled by the build script at ./Build.hs from
the file `./reflections/day02.md`.  If you want to edit this, edit
that file instead!
-->

*[Prompt][d02p]* / *[Code][d02g]*

[d02p]: https://adventofcode.com/2021/day/2
[d02g]: https://github.com/egnwd/advent/blob/2021/src/AOC/Challenge/Day02.hs

Moving around a 2D map, another AoC classic challenge.

My initial solution used recursion and word splitting for the solution,
the second used State, and that too was more difficult to understand, and felt more imperative.

The version here uses Monoids to combine the values (part a ended up similar to my first fold attempt).

To parse we can read many `Sum`mable `Points` and have that as our instruction set.
The parser combinators make this quite nice to do:

```haskell
parser = do
  dir <- pTok $
        (Sum . flip V2 0     <$ "forward")
    <|> (Sum . V2 0 . negate <$ "up")
    <|> (Sum . V2 0          <$ "down")
  dir <$> pDecimal
```

Then to solve part 1 we just need to combine the instructions.
I used the `V2` type from `Linear.V2` to represent points as they are 2D vectors with the added bonus of
being able to easily to component-wise addition of vectors.

```haskell
solve = product . getSum . mconcat
```

After the submarine's epic journey, we get 1 star!

For part two, I wrote a new type `Submarine` with a location and aim.

```haskell
data Submarine = Sub { loc :: Point, aim :: Int }
```

this time to combine we must implement `Monoid`, and first Semigroup.

```haskell
instance Semigroup Submarine where
    (Sub v a) <> (Sub (V2 x' y') a') = Sub (v + V2 x' (y' + x' * a)) (a + a')

instance Monoid Submarine where
    mempty = Sub (pure 0) 0
    mconcat = foldl (<>) mempty
```

`(<>)` combines two commands, adding the forward components `x+x'`,
updates the depth taking into account the previous aim and the forward distance
`y + y' + x' * a` (for the `up` & `down` commands `x'` & `y'` are `0` so that term cancels),
and finally the aim is updated (for `forward` this is `0` so is also a noop).

Then to combine we do similar to part 1:
```haskell
solve = product . loc . mconcat
```

where `loc` gets the vector from the `Submarine` akin to `getSum` getting the vector from `Sum`.

Submarine successfully piloted!


### Day 2 Benchmarks

```
>> Day 02a
benchmarking...
time                 3.811 ms   (3.759 ms .. 3.889 ms)
                     0.997 R²   (0.995 R² .. 0.999 R²)
mean                 3.781 ms   (3.721 ms .. 3.821 ms)
std dev              164.2 μs   (126.4 μs .. 240.8 μs)
variance introduced by outliers: 25% (moderately inflated)

>> Day 02b
benchmarking...
time                 2.332 ms   (2.310 ms .. 2.357 ms)
                     0.999 R²   (0.999 R² .. 1.000 R²)
mean                 2.345 ms   (2.330 ms .. 2.363 ms)
std dev              54.61 μs   (42.35 μs .. 69.57 μs)
variance introduced by outliers: 10% (moderately inflated)
```



Day 3
------

<!--
This section is generated and compiled by the build script at ./Build.hs from
the file `./reflections/day03.md`.  If you want to edit this, edit
that file instead!
-->

*[Prompt][d03p]* / *[Code][d03g]*

[d03p]: https://adventofcode.com/2021/day/3
[d03g]: https://github.com/egnwd/advent/blob/2021/src/AOC/Challenge/Day03.hs

I have not really liked any of the iterations of Day 3, but I learnt something new for this one, so I'm happy with that.

I learnt about [apomorphisms](https://ipfs.io/ipfs/QmTppu1VDAQWsdiyVSZX6qb8PErdpwzNP2oKfEhcgaBvWR/guide-to-morphisms.pdf)!

Before we get there though, let's look at part 1.

We have many rows of binary numbers, so we need to parse the strings into a many lists of bits.
I'm going to use the following data types:

```haskell
type Bit = Finite 2
type Bits = [Bit]

zero, one :: Bit
zero = finite 0
one  = finite 1
```

`Finite 2` represents a number type that has two inhabitants, `0` and `1`.

So in order to parse we can simply do

```haskell
parser :: String -> [Bits]
parser = map (map (finite . fromIntegral . digitToInt)) . lines
```

For part 1 we need to collect a binary number for the most common bits in each column,
and a binary number for the least common bits. We can do this by transposing the matrix of bits so that we are iterating over the columns and getting the most and least significant bit.

```haskell
-- | Count the number of 1s and 0s, then compare
mostCommonBit :: Bits -> Bit
mostCommonBit bs = if ones > zeros then one else zero
    where
        (zeros, ones) = foldr go (0,0) bs
        go :: Bit -> (Int, Int) -> (Int, Int)
        go 0 = first succ
        go 1 = second succ
        go _ = id

-- | Note the least common bit will just be the most common bit flipped
mostAndLeastCommonBit :: Bits -> (Bit, Bit)
mostAndLeastCommonBit bs = let b = mostCommonBit bs in (b, 1-b)

getMostAndLeastCommonBitsPerColumn :: [Bits] -> [(Bit, Bit)]
getMostAndLeastCommonBitsPerColumn = map mostAndLeastCommonBit . transpose
```

Now that we have these values we need to turn the binary numbers to decimals and multiply them together.

```haskell
solve bs = let (gamma, epsilon) = unzip (getMostAndLeastCommonBitsPerColumn bs)
            in gamma * epsilon
```

_If you aren't familiar, `unzip` takes a list of pairs (`[(a,b)]`) and creates a pair of lists `([a], [b])`._

Part 1 done!

Part 2 is where we get into _apomorphisms_.

Firstly, I found [this blog post](https://blog.sumtypeofway.com/posts/recursion-schemes-part-3.html) useful to give an insight into how _apomorphisms_ are constructed.

To very poorly summarise: an _apomorphism_ is the dual of a _paramorphism_, which in turn is a _catamorphism_ but with additional context of the structure that you are recursing on.
A _catamorphism_ is a way to collapse a structure down to some value, and is the most familar of the _-morphisms_,
for example `foldr`, `sum` & `length` are all catamorphisms (I'm pretty sure).
So a _paramorphism_ is a way of collasing a structure down to a value, but at each stage you have some additional context of the unmodified structure. If it helps the types (I'm using the list functor here for ease) look like this:

```haskell
cata :: ([a] ->       b)  -> [a] -> b
para :: ([a] -> ([a], b)) -> [a] -> b
```

So, an _apomorphism_ is the dual of the _paramorphism_, and the way I have tried to think of it (which may be wrong) is:
you take a seed value and build a structure by providing either the rest of the structure, or a bit of the structure and the next seed. The type is roughly:

```haskell
apo :: (b -> Either [a] (a, b)) -> b -> [a]
```

So... how do we use this...

Going back to the problem we need to calculate the oxygen rating and carbon dioxide rating and multiply them together.
To get the oxygen rating we need to find the number matches the **most common bit** of each column by filtering out numbers that don't match until we are left with one.

_From here I will use the non specific type of `apo`._

Here is the base functor for a list.
I'm not going to go into what that is, but the structure looks a lot like a cons list and
it basically has some part of the list structure in the `Cons a` then keeps the rest of the structure in `b`.
For much better information I would recommend [this blog post](https://blog.sumtypeofway.com/posts/recursion-schemes-part-4-point-5.html).

```haskell
data ListF a b = Nil | Cons a b
```

Now we can think about our initial seed: the rows of binary numbers.
And what we can to produce: a list of bits that represent the oxygen rating (for now).

```haskell
oxygen :: [Bits] -> ListF Bit (Either Bits [Bits])
oxygen bs = ...
```

This looks sort of like the type definition from earlier for `apo`, the main difference is the `(a, b)` is now a `ListF` wrapping the `Either`.

The next task for the oxygen rating is to work out the **most common bit** for the column.

```haskell
mcb = (mostCommonBit . map head) bs
```

We can do this by reusing our `mostCommonBit` function from part 1 and running it on the head of each binary number in our seed.

Next, we need to get all the numbers in the seed that start with this `mcb`.

```haskell
ns = filter ((== mcb) . head) bs
```

Again fairly simple, just filter the list where the head is equal to the **most common bit**.

The final part is the interesting part:

```haskell
go = case ns of
    []  -> Nil -- There are no numbers (uh no, the problem might be broken)
    -- If there is only one number left,
    -- return part of the structure: the current mcb cons'd to all the remain bits of the final number
    [n] -> Cons mcb (Left (tail n))
    -- For anything else,
    -- return part of the structure: the current mcb cons'd to the next seed
    -- (all the binary numbers after removing the current column)
    _   -> Cons mcb (Right (map tail ns))
```

Visually it looks a little like doing this:

```
Current seed:

0 | 0 1 0 0
1 | 1 1 1 0
1 | 0 1 1 0
1 | 0 1 1 1

Filtered:

1 | 1 1 1 0
1 | 0 1 1 0
1 | 0 1 1 1

Next Seed:
Cons 1 (
    1 | 1 1 0
    0 | 1 1 0
    0 | 1 1 1)
```

The carbon dioxide follows the same pattern, we just use **least common bit** not **most common bit**.
Finally, we get teh values and multiply them together:

```haskell
solve bs = o * c
    where
        o = binToDec $ apo oxygen bs
        c = binToDec $ apo carbonDioxide bs
```

Phew! and Done!


### Day 3 Benchmarks

```
>> Day 03a
benchmarking...
time                 2.616 ms   (2.580 ms .. 2.653 ms)
                     0.998 R²   (0.996 R² .. 0.999 R²)
mean                 2.579 ms   (2.545 ms .. 2.617 ms)
std dev              127.0 μs   (94.73 μs .. 169.5 μs)
variance introduced by outliers: 31% (moderately inflated)

* parsing and formatting times excluded

>> Day 03b
benchmarking...
time                 509.8 μs   (508.6 μs .. 511.3 μs)
                     1.000 R²   (1.000 R² .. 1.000 R²)
mean                 508.9 μs   (508.1 μs .. 510.1 μs)
std dev              3.314 μs   (2.671 μs .. 4.362 μs)

* parsing and formatting times excluded
```



Day 4
------

<!--
This section is generated and compiled by the build script at ./Build.hs from
the file `./reflections/day04.md`.  If you want to edit this, edit
that file instead!
-->

*[Prompt][d04p]* / *[Code][d04g]*

[d04p]: https://adventofcode.com/2021/day/4
[d04g]: https://github.com/egnwd/advent/blob/2021/src/AOC/Challenge/Day04.hs

Bingo against a giant squid is a funny idea 😆

Today we got to learn about two Semigroups! `First` and `Last`,
they are fairly self explanatory, `First` will give you the left (first) argument to `(<>)`
and `Last` will give you the second (last) argument to `(<>)`.

_N.B. `Last` is the `Dual` of `First`._

To parse we need two things, the list of numbers and all the cards.

```haskell
data BingoNumber = Unmarked Int | Marked Int deriving (Eq, Show)
type BingoCard = [[BingoNumber]]

parse :: String -> ([Int], [BingoCard])
```

Here we can represent a number as either marked or unmarked (note this is just `Either` with a nicer name).

Then we can define our solve function to take the list of numbers, the boards, and return the score, maybe.

```haskell
solve :: [Int] -> [BingoCard] -> Maybe Score
```

(We will look at `Score` later.)

Then as we see a number, `n`, we mark all our cards.

```haskell
newCards n cards = cards'
  where
    cards' = cards <&> mapped.mapped %~ mark
    mark (Unmarked x) | x == n = Marked x
    mark x = x
```

We can define what it means for a card to have won:

```haskell
winner :: BingoCard -> Bool
winner cards = row cards || column cards
    where
        column = row . transpose
        row = any (all isMarked)

isMarked :: BingoNumber -> Bool
isMarked = \case
    Marked _ -> True
    _ -> False
```

Next, we work out the scores for all the winners this round.

```haskell
scoreWinners cards' n = winners
  where
      winners = foldMap (Just . First . scoreCard) w
      w = filter winner cards'
      scoreCard card = (sum . unmarked $ card) * n
      unmarked = map unmarkedValue . concat

unmarkedValue :: BingoNumber -> Int
unmarkedValue (Unmarked n) = n
unmarkedValue (Marked _)   = 0
```

and here is where we get to see `First`.

We've taken our cards and found the winners, then we score them using the score system from the problem statement,
and next we make a `Maybe (First Int)` with `Just . First`. This represents (the maybe is to represent the fact we have a score).

`foldMap` will the return `Nothing` if there are no winners this round, or `Just (First x)` where `x` is the score of the first winner.

We then recurse on the rest of the numbers and the boards that haven't won yet.

```haskell
solve (n:ns) cards = scoreWinners cards' n <> solve ns (filter (not . winner) cards')
  where
    cards' = newCards n cards
```

Now for part two all we need to do is swap `First` for `Last`!!

Now, hopefully the squid doesn't eat us.


### Day 4 Benchmarks

```
>> Day 04a
benchmarking...
time                 15.18 ms   (14.92 ms .. 15.40 ms)
                     0.998 R²   (0.997 R² .. 0.999 R²)
mean                 15.10 ms   (14.94 ms .. 15.24 ms)
std dev              380.8 μs   (270.1 μs .. 579.1 μs)

* parsing and formatting times excluded

>> Day 04b
benchmarking...
time                 20.12 ms   (19.95 ms .. 20.35 ms)
                     1.000 R²   (0.999 R² .. 1.000 R²)
mean                 20.05 ms   (19.94 ms .. 20.14 ms)
std dev              231.6 μs   (169.9 μs .. 321.9 μs)

* parsing and formatting times excluded
```



Day 5
------

<!--
This section is generated and compiled by the build script at ./Build.hs from
the file `./reflections/day05.md`.  If you want to edit this, edit
that file instead!
-->

*[Prompt][d05p]* / *[Code][d05g]*

[d05p]: https://adventofcode.com/2021/day/5
[d05g]: https://github.com/egnwd/advent/blob/2021/src/AOC/Challenge/Day05.hs

Lots of 2D grids!

Another day we get to use the `Linear` package. We can model a line as a 2D vector of points (`V2 (V2 Int)`).

For part 1 we are told to ignore diagonal lines (I wonder what part 2 could possibly be!) so we can filter those easily enough:

```haskell
isHorizontalOrVertical :: V2 (V2 Int) -> Bool
isHorizontalOrVertical (V2 (V2 x1 y1) (V2 x2 y2)) = x1 == x2 || y1 == y2

horizontalOrVerticalLines :: [V2 (V2 Int)] -> [V2 (V2 Int)]
horizontalOrVerticalLines lines = filter isHorizontalOrVertical lines
```

Next, we need to generate the full lines. If we take 2 points `a` & `b` and find their difference `b - a`,
then we can get the vector between them. Reducing this vector to it's simplest form by dividing each component by the greatest common divisor
of the components will give us the smallest possible hops we can make to hit a valid grid point.
We then make little hops and collect the points in a list.

This is a modified version of [mstksg's](https://github.com/mstksg/advent-of-code-2020/blob/master/src/AOC/Common/Point.hs#L371) `lineTo` function from last years AOC.

```haskell
lineTo :: V2 Point -> [Point]
lineTo (V2 p0 p1) = [p0 + t *^ step | t <- [0 .. gcf]]
  where
    d@(V2 dx dy) = p1 - p0
    gcf          = gcd dx dy
    step         = (`div` gcf) <$> d
```

and as the tooltip hinted, we are looking along the lines of plotting lines so the [Bresenham's line algorithm](https://en.wikipedia.org/wiki/Bresenham%27s_line_algorithm#Algorithm_for_integer_arithmetic) is a nice read, though not necessarily useful for the problem other than providing intuition.

Then all we need to do find the frequency of getting all the points from all the line segments:

```haskell
pointFrequencies lines = fromMapWith (+) . map (,1) . concatMap lineTo $ lines
```

Then finally find the number of points that are visited by more than 1 line segment.

```haskell
solve lines = size . filter (>1) . pointFrequencies $ lines
```

Done! 1 star!

As suspected, part 2 removes the horizontal/vertical line restriction, and so we need simply remove our filter.

Hydrothermal vent field successfully navigated!


### Day 5 Benchmarks

```
>> Day 05a
benchmarking...
time                 222.4 ms   (211.9 ms .. 236.0 ms)
                     0.998 R²   (0.994 R² .. 1.000 R²)
mean                 218.0 ms   (214.7 ms .. 222.0 ms)
std dev              5.663 ms   (3.912 ms .. 7.234 ms)
variance introduced by outliers: 14% (moderately inflated)

* parsing and formatting times excluded

>> Day 05b
benchmarking...
time                 381.1 ms   (370.1 ms .. 399.2 ms)
                     1.000 R²   (0.999 R² .. 1.000 R²)
mean                 377.9 ms   (371.5 ms .. 381.7 ms)
std dev              6.356 ms   (2.334 ms .. 8.720 ms)
variance introduced by outliers: 19% (moderately inflated)

* parsing and formatting times excluded
```



Day 6
------

<!--
This section is generated and compiled by the build script at ./Build.hs from
the file `./reflections/day06.md`.  If you want to edit this, edit
that file instead!
-->

*[Prompt][d06p]* / *[Code][d06g]*

[d06p]: https://adventofcode.com/2021/day/6
[d06g]: https://github.com/egnwd/advent/blob/2021/src/AOC/Challenge/Day06.hs

For part 1 today I started with the most naïve approach where I simply generate all the fish and then count them,
fully aware this wouldn't scale, but it might get me the first star.

So for this approach we take a fish and generate a list of fish that come from this fish in the next day.

```haskell
step 0 = [6,8]
step f = [f-1]
```

next we map all of today's fish into their offspring, and join all the lists. Now we simply repeat the process until the nth day and see how many fish we have.

```haskell
solve = length . (!! n) . iterate (concatMap step)
```

Now fortuneately for only 80 days that didn't take to long, onto part 2.

First, I tried what I imagine most people did which was change the number to 256 and rerun.
I was sat there for a while... it didn't work.

In order to speed up the process we can notice something interesting:
if you have a fish that is on day N, over the course of 256 days it will have so many fish descendants,
following some family tree shape. (it's 4726100874 descendants, in case you are curious).

What is more is that if another fish starts on 4, then it will also have 4726100874 descendants.
So we can see that if there are N 4s in the input then we get `N * 4726100874` descendants.

As there are finitely many numbers that the fish can be represented by (0-8) we represent them not as a `[Int]` but as a very small `Map Int Int` where the key is the fish value and the value is the count of fish in that slot.

Everyday, there will be all the fish from the `0` slot making new fish, so we get `n` new fish in the `8` slot and `n` fish into the `6` "reset" slot. All the other fish shift down by one.

At the end of 256 days we can count the numbers in the map to see how many fish there are.

```haskell
solve :: Int -> [Fish] -> Int
solve n = sum . (!! n) . iterate step . freqs

step :: Map Fish Int -> Map Fish Int
step m = M.insertWith (+) 6 newFish . M.mapKeys tickDown $ m
    where
        newFish = m ! 0
        tickDown = maybe 8 weaken . unshift
```

_`maybe 8 weaken . unshift` represents wrapping the numbers around, 6 -> 5, 2 -> 1, and 0 -> 8 (as `unshift 0` will return `Nothing`, so we reset it to 8)_

To me it makes more sense to think about the fish resetting to `8` and new fish coming in at `6`, just so the wrapping and insertion keeps the fish the same... but that's just me.


### Day 6 Benchmarks

```
>> Day 06a
benchmarking...
time                 120.8 μs   (120.6 μs .. 121.1 μs)
                     1.000 R²   (1.000 R² .. 1.000 R²)
mean                 120.9 μs   (120.6 μs .. 121.3 μs)
std dev              1.187 μs   (932.3 ns .. 1.760 μs)

* parsing and formatting times excluded

>> Day 06b
benchmarking...
time                 402.4 μs   (400.9 μs .. 404.4 μs)
                     1.000 R²   (1.000 R² .. 1.000 R²)
mean                 400.2 μs   (399.0 μs .. 401.9 μs)
std dev              4.823 μs   (3.643 μs .. 6.416 μs)

* parsing and formatting times excluded
```



Day 7
------

<!--
This section is generated and compiled by the build script at ./Build.hs from
the file `./reflections/day07.md`.  If you want to edit this, edit
that file instead!
-->

*[Prompt][d07p]* / *[Code][d07g]*

[d07p]: https://adventofcode.com/2021/day/7
[d07g]: https://github.com/egnwd/advent/blob/2021/src/AOC/Challenge/Day07.hs

I feel like there is a better solution for today that avoids checking all points, but for now here is the naïve version:

For part 1 we need a way of scoring a particular horizontal position.
The score here is the sum of the absolute differences from the crabs to the position in question.

```haskell
score :: [Int] -> Int -> Int
score crabs position = sum . map (abs . subtract position) $ crabs
```

The we need to check all the positions from the minimum crab to the maximum crab.

```haskell
solve [Int] -> Int
solve crabs = minimum . map (score crabs) $ [minimum cs .. maximum cs]
```

And there we go!

For part 2, then need to confess my original implementation of part 1 was:

```haskell
solve [Int] -> Int
solve crabs = minimum . map (score crabs) $ crabs
```

as I assumed we had to pick a crab for them to congregate on,
and one of my crabs was on the right spot.

For part 2 I then just needed to tweak the score function to be

```haskell
triangularNumber :: Int -> Int
triangularNumber x = x * (x + 1) `div` 2

score :: [Int] -> Int -> Int
score crabs position = sum . map (triangularNumber . abs . subtract position) $ crabs
```

_...and then you debug why you can't get the right answer and think you can no longer remember what a triangular number is for 20 minutes,
despite watching absurds amounts of [sudoku videos](https://www.youtube.com/c/CrackingTheCryptic)..._

...until you realise all the crabs could congregate on any of the spots.

_sigh._


### Day 7 Benchmarks

```
>> Day 07a
benchmarking...
time                 32.43 ms   (32.06 ms .. 32.90 ms)
                     0.999 R²   (0.999 R² .. 1.000 R²)
mean                 31.91 ms   (31.36 ms .. 32.27 ms)
std dev              947.0 μs   (535.8 μs .. 1.565 ms)

* parsing and formatting times excluded

>> Day 07b
benchmarking...
time                 2.616 s    (NaN s .. 2.654 s)
                     1.000 R²   (1.000 R² .. 1.000 R²)
mean                 2.597 s    (2.591 s .. 2.607 s)
std dev              9.376 ms   (1.954 ms .. 12.41 ms)
variance introduced by outliers: 19% (moderately inflated)

* parsing and formatting times excluded
```



Day 8
------

<!--
This section is generated and compiled by the build script at ./Build.hs from
the file `./reflections/day08.md`.  If you want to edit this, edit
that file instead!
-->

*[Prompt][d08p]* / *[Code][d08g]*

[d08p]: https://adventofcode.com/2021/day/8
[d08g]: https://github.com/egnwd/advent/blob/2021/src/AOC/Challenge/Day08.hs

*Reflection not yet written -- please check back later!*

### Day 8 Benchmarks

```
>> Day 08a
benchmarking...
time                 5.454 ms   (5.400 ms .. 5.518 ms)
                     0.998 R²   (0.997 R² .. 0.999 R²)
mean                 5.501 ms   (5.439 ms .. 5.623 ms)
std dev              270.0 μs   (184.1 μs .. 397.3 μs)
variance introduced by outliers: 26% (moderately inflated)

>> Day 08b
benchmarking...
time                 13.95 ms   (13.58 ms .. 14.56 ms)
                     0.993 R²   (0.984 R² .. 1.000 R²)
mean                 13.67 ms   (13.54 ms .. 14.00 ms)
std dev              477.7 μs   (169.0 μs .. 834.5 μs)
variance introduced by outliers: 11% (moderately inflated)
```



Day 9
------

<!--
This section is generated and compiled by the build script at ./Build.hs from
the file `./reflections/day09.md`.  If you want to edit this, edit
that file instead!
-->

*[Prompt][d09p]* / *[Code][d09g]*

[d09p]: https://adventofcode.com/2021/day/9
[d09g]: https://github.com/egnwd/advent/blob/2021/src/AOC/Challenge/Day09.hs

Part 1 today was simple enough.

Firstly we can parse in the numbers as a `Map (V2 Int) Int`,
and as a cheat for later we can ignore all the spots with `9`, you can imagine them as "super high walls" in our map.

```haskell
type Landscape = Map (V2 Int) Int

parse :: String -> Landscape
parse = parseAsciiMap (mfilter (<9) . pure . digitToInt)
```

where `parseAsciiMap` is a helper method that zips the indexes of a grid with the value,
and a method for generating the value, `Nothing` removes it from the map and `Just x` places `x` into the map.

To find the low points we can filter the map to entries that have values lower than all the neighbours.
To do that we get all the neighbours by adding "North", "East", "South" and "West" to the index in the map (the key).
_N.B. this might result in a point off the map!_

Then we ensure that the current value is less than all these points (if they exist!)
Finally, we can sum all the scores of the low points.

```haskell
score :: Int -> Sum Int
score n = Sum (1+n)

neighbours k = (k +) <$> [V2 0 (-1), V2 1 0, V2 0 1, V2 (-1) 0]

solvea :: Landscape -> Int
solvea = getSum . foldMapWithKey (const score) . findLowPoints
  where
    findLowPoints nss = M.filterWithKey isLowest nss
    isLowest k h = all (maybe True (h <) . (`M.lookup` nss)) (neighbours k)
```

Now for part 2!

For part 2, I used another _apomorphism_! We are tasked with find the product of the sizes of the 3 largest basins.
Our first task is to find the sizes of the basins. All basins have a sink which is the lowest point, so we can map over these and build the basin from this _seed point_.

First let's generate the seeds, we simply find the low points as before, get the locations and turn it into a tuple of `(seen, pointsToCompute)`:

```haskell
lowPointSeeds = map (\l -> (S.empty, S.singleton l)) . M.keys . findLowPoints $ land
```

now we build our basins from a given seed.

```haskell
buildBasin
    :: M.Map Point (S.Set Point)                           -- | Map from point to neighbouring values
    -> Landscape                                           -- | Original grid
    -> (S.Set Point, S.Set Point)                          -- | Seen points, and next points
    -> ListF Int (Either [Int] (S.Set Point, S.Set Point)) -- | ListF of current region sizes over the next regions to visit
buildBasin ns land (seen, next) = Cons (S.size next) go
    where
        neighbouringBasinLocations = M.keysSet . M.restrictKeys land . S.unions . S.map (fromMaybe S.empty . (`M.lookup` ns))
        next' = neighbouringBasinLocations next `S.difference` seen
        seen' = S.union seen next
        go = if null next'
                then Left []
                else Right (seen', next')
```

Here we find all the neighbouring basin locations by looking up the neighbours for our each of our next points to look at,
We then union all these neighbouring points, and intersect the points with our land (to remove any off the edge).

We then remove from this set all the points we've seen before.

If there is nothing in this set we have found the full region, so we finish by returning `Left []`,
otherwise we return `Right (seen', next')` where `seen'` is the union of what we've seen with the points we have just computed.

To build the `ListF` functor we have `Cons (S.size next)` which adds the size of the sub-basin we have just computed to the list.

Then to get the sum we run `sum . apo (buildBasin allNeighbours land) $ lowPointSeeds` where

```haskell
allNeighbours = M.mapWithKey (const . S.fromList . neighbours) land
```

now that we have all the region sizes we find the largest 3 and get the product.

```haskell
solveb :: Landscape -> Int
solveb land = product . largest 3 . map getBasinSize $ lowPointSeeds
    where
        largest n = take n . sortOn negate
        getBasinSize = sum . apo (buildBasin allNeighbours land)
        allNeighbours = M.mapWithKey (const . S.fromList . neighbours) land
        lowPointSeeds = map (\l -> (S.empty, S.singleton l)) . M.keys . findLowPoints $ land
```

And there we are!


### Day 9 Benchmarks

```
>> Day 09a
benchmarking...
time                 16.80 ms   (16.69 ms .. 16.90 ms)
                     1.000 R²   (0.999 R² .. 1.000 R²)
mean                 16.82 ms   (16.76 ms .. 16.90 ms)
std dev              170.5 μs   (115.6 μs .. 283.9 μs)

* parsing and formatting times excluded

>> Day 09b
benchmarking...
time                 42.39 ms   (42.21 ms .. 42.52 ms)
                     1.000 R²   (1.000 R² .. 1.000 R²)
mean                 42.62 ms   (42.48 ms .. 42.87 ms)
std dev              362.9 μs   (216.1 μs .. 577.9 μs)

* parsing and formatting times excluded
```



Day 10
------

<!--
This section is generated and compiled by the build script at ./Build.hs from
the file `./reflections/day10.md`.  If you want to edit this, edit
that file instead!
-->

*[Prompt][d10p]* / *[Code][d10g]*

[d10p]: https://adventofcode.com/2021/day/10
[d10g]: https://github.com/egnwd/advent/blob/2021/src/AOC/Challenge/Day10.hs

*Reflection not yet written -- please check back later!*

### Day 10 Benchmarks

```
>> Day 10a
benchmarking...
time                 430.3 μs   (428.7 μs .. 432.4 μs)
                     1.000 R²   (1.000 R² .. 1.000 R²)
mean                 431.3 μs   (429.8 μs .. 433.5 μs)
std dev              6.484 μs   (3.791 μs .. 9.634 μs)

* parsing and formatting times excluded

>> Day 10b
benchmarking...
time                 489.7 μs   (483.7 μs .. 501.2 μs)
                     0.996 R²   (0.990 R² .. 1.000 R²)
mean                 489.7 μs   (484.4 μs .. 501.1 μs)
std dev              24.51 μs   (11.37 μs .. 42.20 μs)
variance introduced by outliers: 44% (moderately inflated)

* parsing and formatting times excluded
```

